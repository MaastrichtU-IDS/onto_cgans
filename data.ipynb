{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbf2be2",
   "metadata": {},
   "source": [
    "## Data pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c024d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the whole notebook\n",
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606da578",
   "metadata": {},
   "source": [
    "### Convert XML dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1344a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: clinical signs and symptoms in rare diseases\n",
    "# http://www.orphadata.org/cgi-bin/index.php (Phenotypes associated with rare disorders)\n",
    "tree = ET.parse('data/en_product4.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "\n",
    "headers = ['HPODisorderSetStatus_id', 'Disorder_id', 'OrphaCode', 'ExpertLink', 'Name', 'DisorderType_id',\n",
    "            'DisorderType_name', 'DisorderGroup_id', 'DisorderGroup_Name', 'HPODisorderAssociation_id',\n",
    "            'HPO_id', 'HPOId', 'HPOTerm', 'HPOFrequency_id', 'HPOFrequency_Name', 'DiagnosticCriteria_id',\n",
    "            'DiagnosticCriteria_Name', 'Source', 'ValidationStatus', 'Online', 'ValidationDate']\n",
    "\n",
    "\n",
    "def find_value(row_data, source_tag, target_tag_name, field, text=True):\n",
    "    \"\"\"Finds a sub-tag of a source tag and inputs its value into a dictionary containing the current row's data\n",
    "    \n",
    "    Args:\n",
    "        row_data (dict):\n",
    "            The data for the current row associated with the csv fields\n",
    "        source_tag (Element):\n",
    "            XML parent tag to search from\n",
    "        target_tag_name (str):\n",
    "            Name of the sub-tag to find\n",
    "        field (str):\n",
    "            Field in the csv file\n",
    "        text (bool):\n",
    "            Indicates if the value of the tag to retrieve is its inner text or its id attribute\n",
    "    Returns:\n",
    "        tag (Element):\n",
    "            Returns the found tag\n",
    "    \"\"\"\n",
    "    tag = source_tag.find(target_tag_name)\n",
    "    tag_v = ''\n",
    "    \n",
    "    if tag is not None:  #retrieving either the inner text or the id attribute of the tag\n",
    "        if text: tag_v = tag.text\n",
    "        elif (len(tag.attrib) > 0): tag_v = tag.attrib['id']\n",
    "    row_data[field] = tag_v if tag_v is not None else ''\n",
    "    \n",
    "    return tag\n",
    "\n",
    "\n",
    "with open('data/en_product4.csv', 'w', encoding='utf-8') as fd:\n",
    "    csvwriter = csv.DictWriter(fd, delimiter=',', fieldnames=headers)\n",
    "    csvwriter.writeheader()\n",
    "    \n",
    "    # iterating through all the disorders\n",
    "    for status in root.find('HPODisorderSetStatusList').findall('HPODisorderSetStatus'):\n",
    "        row_data = {}\n",
    "        row_data['HPODisorderSetStatus_id'] = status.attrib['id']\n",
    "        \n",
    "        disorder_tag = find_value(row_data, status, 'Disorder', 'Disorder_id', text=False)\n",
    "        find_value(row_data, disorder_tag, 'OrphaCode', 'OrphaCode', text=True)\n",
    "        find_value(row_data, disorder_tag, 'ExpertLink', 'ExpertLink', text=True)\n",
    "        find_value(row_data, disorder_tag, 'Name', 'Name', text=True)\n",
    "        \n",
    "        disordertype_tag = find_value(row_data, disorder_tag, 'DisorderType', 'DisorderType_id', text=False)\n",
    "        find_value(row_data, disordertype_tag, 'Name', 'DisorderType_name', text=True)\n",
    "        disordergroup_tag = find_value(row_data, disorder_tag, 'DisorderGroup', 'DisorderGroup_id', text=False)\n",
    "        find_value(row_data, disordergroup_tag, 'Name', 'DisorderGroup_Name', text=True)\n",
    "        \n",
    "        for field in ['Source', 'ValidationStatus', 'Online', 'ValidationDate']:\n",
    "            find_value(row_data, status, field, field, text=True)\n",
    "        \n",
    "        # iterating through all the disorder associations and writing a row for each\n",
    "        for association in disorder_tag.find('HPODisorderAssociationList').findall('HPODisorderAssociation'):\n",
    "            row_data['HPODisorderAssociation_id'] = association.attrib['id']\n",
    "            \n",
    "            hpo_tag = find_value(row_data, association, 'HPO', 'HPO_id', text=False)\n",
    "            find_value(row_data, hpo_tag, 'HPOId', 'HPOId', text=True)\n",
    "            find_value(row_data, hpo_tag, 'HPOTerm', 'HPOTerm', text=True)\n",
    "            hpofrequency_tag = find_value(row_data, association, 'HPOFrequency', 'HPOFrequency_id', text=False)\n",
    "            find_value(row_data, hpofrequency_tag, 'Name', 'HPOFrequency_Name', text=True)\n",
    "            \n",
    "            diagnosticcriteria_tag = find_value(row_data, association, 'DiagnosticCriteria', 'DiagnosticCriteria_id', text=False)\n",
    "            find_value(row_data, diagnosticcriteria_tag, 'Name', 'DiagnosticCriteria_Name', text=True)\n",
    "            \n",
    "            csvwriter.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebdae01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HPODisorderSetStatus_id</th>\n",
       "      <th>Disorder_id</th>\n",
       "      <th>OrphaCode</th>\n",
       "      <th>ExpertLink</th>\n",
       "      <th>Name</th>\n",
       "      <th>DisorderType_id</th>\n",
       "      <th>DisorderType_name</th>\n",
       "      <th>DisorderGroup_id</th>\n",
       "      <th>DisorderGroup_Name</th>\n",
       "      <th>HPODisorderAssociation_id</th>\n",
       "      <th>...</th>\n",
       "      <th>HPOId</th>\n",
       "      <th>HPOTerm</th>\n",
       "      <th>HPOFrequency_id</th>\n",
       "      <th>HPOFrequency_Name</th>\n",
       "      <th>DiagnosticCriteria_id</th>\n",
       "      <th>DiagnosticCriteria_Name</th>\n",
       "      <th>Source</th>\n",
       "      <th>ValidationStatus</th>\n",
       "      <th>Online</th>\n",
       "      <th>ValidationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>http://www.orpha.net/consor/cgi-bin/OC_Exp.php...</td>\n",
       "      <td>Alexander disease</td>\n",
       "      <td>21394</td>\n",
       "      <td>Disease</td>\n",
       "      <td>36547</td>\n",
       "      <td>Disorder</td>\n",
       "      <td>327485</td>\n",
       "      <td>...</td>\n",
       "      <td>HP:0000256</td>\n",
       "      <td>Macrocephaly</td>\n",
       "      <td>28412</td>\n",
       "      <td>Very frequent (99-80%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2016-06-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>http://www.orpha.net/consor/cgi-bin/OC_Exp.php...</td>\n",
       "      <td>Alexander disease</td>\n",
       "      <td>21394</td>\n",
       "      <td>Disease</td>\n",
       "      <td>36547</td>\n",
       "      <td>Disorder</td>\n",
       "      <td>327486</td>\n",
       "      <td>...</td>\n",
       "      <td>HP:0001249</td>\n",
       "      <td>Intellectual disability</td>\n",
       "      <td>28412</td>\n",
       "      <td>Very frequent (99-80%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2016-06-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>http://www.orpha.net/consor/cgi-bin/OC_Exp.php...</td>\n",
       "      <td>Alexander disease</td>\n",
       "      <td>21394</td>\n",
       "      <td>Disease</td>\n",
       "      <td>36547</td>\n",
       "      <td>Disorder</td>\n",
       "      <td>327487</td>\n",
       "      <td>...</td>\n",
       "      <td>HP:0001250</td>\n",
       "      <td>Seizures</td>\n",
       "      <td>28412</td>\n",
       "      <td>Very frequent (99-80%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2016-06-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>http://www.orpha.net/consor/cgi-bin/OC_Exp.php...</td>\n",
       "      <td>Alexander disease</td>\n",
       "      <td>21394</td>\n",
       "      <td>Disease</td>\n",
       "      <td>36547</td>\n",
       "      <td>Disorder</td>\n",
       "      <td>327488</td>\n",
       "      <td>...</td>\n",
       "      <td>HP:0001257</td>\n",
       "      <td>Spasticity</td>\n",
       "      <td>28412</td>\n",
       "      <td>Very frequent (99-80%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2016-06-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>http://www.orpha.net/consor/cgi-bin/OC_Exp.php...</td>\n",
       "      <td>Alexander disease</td>\n",
       "      <td>21394</td>\n",
       "      <td>Disease</td>\n",
       "      <td>36547</td>\n",
       "      <td>Disorder</td>\n",
       "      <td>327489</td>\n",
       "      <td>...</td>\n",
       "      <td>HP:0001274</td>\n",
       "      <td>Agenesis of corpus callosum</td>\n",
       "      <td>28412</td>\n",
       "      <td>Very frequent (99-80%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2016-06-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HPODisorderSetStatus_id  Disorder_id  OrphaCode  \\\n",
       "0                        1            2         58   \n",
       "1                        1            2         58   \n",
       "2                        1            2         58   \n",
       "3                        1            2         58   \n",
       "4                        1            2         58   \n",
       "\n",
       "                                          ExpertLink               Name  \\\n",
       "0  http://www.orpha.net/consor/cgi-bin/OC_Exp.php...  Alexander disease   \n",
       "1  http://www.orpha.net/consor/cgi-bin/OC_Exp.php...  Alexander disease   \n",
       "2  http://www.orpha.net/consor/cgi-bin/OC_Exp.php...  Alexander disease   \n",
       "3  http://www.orpha.net/consor/cgi-bin/OC_Exp.php...  Alexander disease   \n",
       "4  http://www.orpha.net/consor/cgi-bin/OC_Exp.php...  Alexander disease   \n",
       "\n",
       "   DisorderType_id DisorderType_name  DisorderGroup_id DisorderGroup_Name  \\\n",
       "0            21394           Disease             36547           Disorder   \n",
       "1            21394           Disease             36547           Disorder   \n",
       "2            21394           Disease             36547           Disorder   \n",
       "3            21394           Disease             36547           Disorder   \n",
       "4            21394           Disease             36547           Disorder   \n",
       "\n",
       "   HPODisorderAssociation_id  ...       HPOId                      HPOTerm  \\\n",
       "0                     327485  ...  HP:0000256                 Macrocephaly   \n",
       "1                     327486  ...  HP:0001249      Intellectual disability   \n",
       "2                     327487  ...  HP:0001250                     Seizures   \n",
       "3                     327488  ...  HP:0001257                   Spasticity   \n",
       "4                     327489  ...  HP:0001274  Agenesis of corpus callosum   \n",
       "\n",
       "  HPOFrequency_id       HPOFrequency_Name DiagnosticCriteria_id  \\\n",
       "0           28412  Very frequent (99-80%)                   NaN   \n",
       "1           28412  Very frequent (99-80%)                   NaN   \n",
       "2           28412  Very frequent (99-80%)                   NaN   \n",
       "3           28412  Very frequent (99-80%)                   NaN   \n",
       "4           28412  Very frequent (99-80%)                   NaN   \n",
       "\n",
       "   DiagnosticCriteria_Name Source ValidationStatus Online  \\\n",
       "0                      NaN    NaN                y      y   \n",
       "1                      NaN    NaN                y      y   \n",
       "2                      NaN    NaN                y      y   \n",
       "3                      NaN    NaN                y      y   \n",
       "4                      NaN    NaN                y      y   \n",
       "\n",
       "          ValidationDate  \n",
       "0  2016-06-01 00:00:00.0  \n",
       "1  2016-06-01 00:00:00.0  \n",
       "2  2016-06-01 00:00:00.0  \n",
       "3  2016-06-01 00:00:00.0  \n",
       "4  2016-06-01 00:00:00.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/en_product4.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36b9de",
   "metadata": {},
   "source": [
    "### Merge ORDO, HP and HOOM ontologies (OWL)\n",
    "\n",
    "https://bioportal.bioontology.org/ontologies/ORDO?p=summary\n",
    "\n",
    "https://bioportal.bioontology.org/ontologies/HP?p=summary\n",
    "\n",
    "https://bioportal.bioontology.org/ontologies/HOOM?p=summary\n",
    "\n",
    "Using Protégé, merge HP into HOOM and ORDO into HOOM\n",
    "\n",
    "'HOOM is a module that qualifies the annotation between a clinical entity and phenotypic abnormalities according to a frequency and by integrating the notion of diagnostic criterion.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04701ac8",
   "metadata": {},
   "source": [
    "### Merge ORDO and HP ontologies using the dataset (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordo = pd.read_csv('data/ORDO.csv', dtype='object')\n",
    "df_hp = pd.read_csv('data/HP.csv', dtype='object')\n",
    "df_dataset = pd.read_csv('data/en_product4.csv', dtype='object')\n",
    "\n",
    "\n",
    "# prefixes to distinguish the columns from the 2 ontologies\n",
    "df_ordo = df_ordo.add_prefix('ORDO_')\n",
    "df_hp = df_hp.add_prefix('HP_')\n",
    "\n",
    "# normalizing the different columns for the merge\n",
    "df_ordo['OrphaCode'] = df_ordo['ORDO_Class ID'].map(lambda x: x.replace('http://www.orpha.net/ORDO/Orphanet_', ''))\n",
    "df_hp['HPOId'] = df_hp['HP_http://www.w3.org/2004/02/skos/core#notation']\n",
    "df_dataset['OrphaCode'] = df_dataset['OrphaCode'].astype(str)\n",
    "\n",
    "# merge\n",
    "df_merged = pd.merge(df_dataset, df_hp, how='left', on='HPOId')\n",
    "df_merged = pd.merge(df_merged, df_ordo, how='left', on='OrphaCode')\n",
    "\n",
    "df_merged.head(1000).to_csv('data/merged_ontologies.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8362bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('data/en_product4.csv', dtype='object')\n",
    "df_res = pd.read_csv('data/merged_ontologies.csv', dtype='object')\n",
    "print(df_dataset.shape)\n",
    "print(df_res.shape)\n",
    "print(df_res[['Name', 'HPOId', 'HP_Class ID', 'ORDO_Class ID']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058d15c",
   "metadata": {},
   "source": [
    "### Dataset to triples, entities and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "793735e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_assoc = {  # from csv frequency to frequency code\n",
    "    'Obligate (100%)': 'O',\n",
    "    'Very frequent (99-80%)': 'VF',\n",
    "    'Frequent (79-30%)': 'F',\n",
    "    'Occasional (29-5%)': 'OC',\n",
    "    'Very rare (<4-1%)': 'VR',\n",
    "    'Excluded (0%)': 'E'\n",
    "}\n",
    "\n",
    "freq_code_assoc = {  # from frequency code to output class\n",
    "    'O': 'obligate',\n",
    "    'VF': 'very_frequent',\n",
    "    'F': 'frequent',\n",
    "    'OC': 'occasional',\n",
    "    'VR': 'very_rare',\n",
    "    'E': 'excluded'\n",
    "}\n",
    "\n",
    "dc_association = {  # default: exclusion\n",
    "    'Diagnostic criterion': 'diagnostic_criterion',\n",
    "    'Pathognomonic sign': 'pathognomonic_sign',\n",
    "}\n",
    "\n",
    "\n",
    "def get_association_subclass(orpha, freq, hp):\n",
    "    \"\"\"Returns normalized association class\n",
    "    \n",
    "    Args:\n",
    "        orpha (str):\n",
    "            The prefixed Orphanet code\n",
    "        freq (str):\n",
    "            The frequency text\n",
    "        hp (str):\n",
    "            The prefixed HPO ID\n",
    "    Returns:\n",
    "        (str):\n",
    "            The orphacode, hpo id and frequency association\n",
    "    \"\"\"\n",
    "    return orpha + '_' + hp + '_FREQ:' + freq_assoc.get(freq)\n",
    "\n",
    "\n",
    "def get_association_name(orpha, freq, hp):\n",
    "    \"\"\"Returns textual description of the association class\n",
    "    \n",
    "    Args:\n",
    "        orpha (str):\n",
    "            The prefixed Orphanet code\n",
    "        freq (str):\n",
    "            The frequency text\n",
    "        hp (str):\n",
    "            The prefixed HPO ID\n",
    "    Returns:\n",
    "        (str):\n",
    "            The orphacode, hpo id and frequency association textual_description_with_underscores\n",
    "    \"\"\"\n",
    "    return get_normalized_string(orpha_entities.get(orpha) + ' and ' + hpo_entities.get(hp) +\\\n",
    "            ' ' + freq_code_assoc.get(freq_assoc.get(freq)) + ' association')\n",
    "\n",
    "\n",
    "def get_normalized_string(s):\n",
    "    \"\"\"Transforms a string to lowercase and replaces all whitespace runs with an underscore\n",
    "    \n",
    "    Args:\n",
    "        s (str):\n",
    "            String to normalize\n",
    "    Returns:\n",
    "        (str):\n",
    "            Normalized string\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s+\", '_', s.lower())\n",
    "\n",
    "\n",
    "df_dataset = pd.read_csv('data/en_product4.csv', dtype='object')\n",
    "df_dataset['OrphaCode'] = df_dataset['OrphaCode'].map(lambda x: 'ORPHA:' + x)\n",
    "\n",
    "# key is id, value is textual_description_with_underscores\n",
    "assoc_entities = {}\n",
    "dc_entities = {'diagnostic_criterion': 'diagnostic_criterion', 'pathognomonic_sign': 'pathognomonic_sign', 'exclusion':'exclusion'}\n",
    "freq_assoc_entities = {'obligate': 'obligate', 'very_frequent': 'very_frequent', 'frequent': 'frequent', \n",
    "                       'occasional': 'occasional', 'very_rare': 'very_rare', 'excluded': 'excluded'}\n",
    "hpo_entities = {}\n",
    "orpha_entities = {}\n",
    "\n",
    "has_object_triples = []  # association has_object HPOId\n",
    "has_subject_triples = []  # association has_subject OrphaCode\n",
    "has_frequency_triples = []  # association has_frequency FrequencyAssociation\n",
    "has_diagnostic_criterion_triples = []  # association has_DC_attribute DC\n",
    "\n",
    "\n",
    "# reading the dataset\n",
    "for orpha, freq, hp, dc, orpha_name, hpo_name in zip(df_dataset['OrphaCode'], df_dataset['HPOFrequency_Name'], \n",
    "                                                     df_dataset['HPOId'], df_dataset['DiagnosticCriteria_Name'], \n",
    "                                                     df_dataset['Name'], df_dataset['HPOTerm']):\n",
    "    if hp not in hpo_entities: hpo_entities[hp] = get_normalized_string(hpo_name)\n",
    "    if orpha not in orpha_entities: orpha_entities[orpha] = get_normalized_string(orpha_name)\n",
    "    ac = get_association_subclass(orpha, freq, hp)\n",
    "    ac_name = get_association_name(orpha, freq, hp)\n",
    "    assoc_entities[ac] = ac_name\n",
    "    has_object_triples.append((ac, 'association_has_object', hp))\n",
    "    has_subject_triples.append((ac, 'association_has_subject', orpha))\n",
    "    if (freq_code_assoc.get(freq_assoc.get(freq)) is None): print('a: ', freq)\n",
    "    has_frequency_triples.append((ac, 'has_frequency', freq_code_assoc.get(freq_assoc.get(freq))))\n",
    "    has_diagnostic_criterion_triples.append((ac, 'has_DC_attribute', dc_association.get(dc, 'exclusion')))\n",
    "\n",
    "    \n",
    "# lists corresponding to each output file\n",
    "triples = []\n",
    "triples_names = []\n",
    "entities = []\n",
    "entities_names = []\n",
    "relations = []\n",
    "\n",
    "# subClassOf triples\n",
    "for k, v in assoc_entities.items(): \n",
    "    triples.append((k, 'subClassOf', 'association'))\n",
    "    triples_names.append((v, 'subClassOf', 'association'))\n",
    "for k, v in dc_entities.items(): \n",
    "    triples.append((k, 'subClassOf', 'diagnostic_criterion'))\n",
    "    triples_names.append((v, 'subClassOf', 'diagnostic_criterion'))\n",
    "for k, v in freq_assoc_entities.items(): \n",
    "    triples.append((k, 'subClassOf', 'frequency_association'))\n",
    "    triples_names.append((v, 'subClassOf', 'frequency_association'))\n",
    "for k, v in hpo_entities.items(): \n",
    "    triples.append((k, 'subClassOf', 'HPO_Id'))\n",
    "    triples_names.append((v, 'subClassOf', 'HPO_Id'))\n",
    "for k, v in orpha_entities.items(): \n",
    "    triples.append((k, 'subClassOf', 'OrphaCode'))\n",
    "    triples_names.append((v, 'subClassOf', 'OrphaCode'))\n",
    "\n",
    "# other properties triples\n",
    "for (s, r, o) in has_object_triples:\n",
    "    triples.append((s, r, o))\n",
    "    triples_names.append((assoc_entities.get(s), r, hpo_entities.get(o)))\n",
    "for (s, r, o) in has_subject_triples:\n",
    "    triples.append((s, r, o))\n",
    "    triples_names.append((assoc_entities.get(s), r, orpha_entities.get(o)))\n",
    "for (s, r, o) in has_frequency_triples:\n",
    "    triples.append((s, r, o))\n",
    "    triples_names.append((assoc_entities.get(s), r, o))\n",
    "for (s, r, o) in has_diagnostic_criterion_triples:\n",
    "    triples.append((s, r, o))\n",
    "    triples_names.append((assoc_entities.get(s), r, o))\n",
    "\n",
    "# entities\n",
    "for i, (k, v) in enumerate({**assoc_entities, **dc_entities, **freq_assoc_entities, **hpo_entities, **orpha_entities}.items()):\n",
    "    entities.append((i, k))\n",
    "    entities_names.append((i, v))\n",
    "\n",
    "# relations\n",
    "for i, r in enumerate(['subClassOf', 'association_has_object', 'association_has_subject', 'has_frequency', 'has_DC_attribute']):\n",
    "    relations.append((i, r))\n",
    "    \n",
    "\n",
    "# writing to the different files\n",
    "with open('data/triples.txt', 'w') as f:\n",
    "    for t in triples:\n",
    "        f.write('\\t'.join(t) + '\\n')\n",
    "with open('data/triples_names.txt', 'w') as f:\n",
    "    for t in triples_names:\n",
    "        f.write('\\t'.join(t) + '\\n')\n",
    "with open('data/entities.dict', 'w') as f:\n",
    "    for t in entities:\n",
    "        f.write('\\t'.join(str(e) for e in t) + '\\n')\n",
    "with open('data/entities_names.dict', 'w') as f:\n",
    "    for t in entities_names:\n",
    "        f.write('\\t'.join(str(e) for e in t) + '\\n')\n",
    "with open('data/relations.dict', 'w') as f:\n",
    "    for t in relations:\n",
    "        f.write('\\t'.join(str(e) for e in t) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onto_cgans",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

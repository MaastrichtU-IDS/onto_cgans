{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e378be34",
   "metadata": {},
   "source": [
    "## Code from OntoZSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba349da4",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2fc82e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, triples, nentity, nrelation, negative_sample_size, mode):\n",
    "        self.len = len(triples)\n",
    "        self.triples = triples\n",
    "        self.triple_set = set(triples)\n",
    "        self.nentity = nentity\n",
    "        self.nrelation = nrelation\n",
    "        self.negative_sample_size = negative_sample_size\n",
    "        self.mode = mode\n",
    "        self.count = self.count_frequency(triples)\n",
    "        self.true_head, self.true_tail = self.get_true_head_and_tail(self.triples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        positive_sample = self.triples[idx]\n",
    "\n",
    "        head, relation, tail = positive_sample\n",
    "\n",
    "        subsampling_weight = self.count[(head, relation)] + self.count[(tail, -relation - 1)]\n",
    "        subsampling_weight = torch.sqrt(1 / torch.Tensor([subsampling_weight]))\n",
    "\n",
    "        negative_sample_list = []\n",
    "        negative_sample_size = 0\n",
    "\n",
    "        while negative_sample_size < self.negative_sample_size:\n",
    "            negative_sample = np.random.randint(self.nentity, size=self.negative_sample_size * 2)\n",
    "            if self.mode == 'head-batch':\n",
    "                mask = np.in1d(\n",
    "                    negative_sample,\n",
    "                    self.true_head[(relation, tail)],\n",
    "                    assume_unique=True,\n",
    "                    invert=True\n",
    "                )\n",
    "            elif self.mode == 'tail-batch':\n",
    "                mask = np.in1d(\n",
    "                    negative_sample,\n",
    "                    self.true_tail[(head, relation)],\n",
    "                    assume_unique=True,\n",
    "                    invert=True\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError('Training batch mode %s not supported' % self.mode)\n",
    "            negative_sample = negative_sample[mask]\n",
    "            negative_sample_list.append(negative_sample)\n",
    "            negative_sample_size += negative_sample.size\n",
    "\n",
    "        negative_sample = np.concatenate(negative_sample_list)[:self.negative_sample_size]\n",
    "\n",
    "        negative_sample = torch.from_numpy(negative_sample)\n",
    "\n",
    "        positive_sample = torch.LongTensor(positive_sample)\n",
    "\n",
    "        return positive_sample, negative_sample, subsampling_weight, self.mode\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(data):\n",
    "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
    "        negative_sample = torch.stack([_[1] for _ in data], dim=0)\n",
    "        subsample_weight = torch.cat([_[2] for _ in data], dim=0)\n",
    "        mode = data[0][3]\n",
    "        return positive_sample, negative_sample, subsample_weight, mode\n",
    "\n",
    "    @staticmethod\n",
    "    def count_frequency(triples, start=4):\n",
    "        '''\n",
    "        Get frequency of a partial triple like (head, relation) or (relation, tail)\n",
    "        The frequency will be used for subsampling like word2vec\n",
    "        '''\n",
    "        count = {}\n",
    "        for head, relation, tail in triples:\n",
    "            if (head, relation) not in count:\n",
    "                count[(head, relation)] = start\n",
    "            else:\n",
    "                count[(head, relation)] += 1\n",
    "\n",
    "            if (tail, -relation - 1) not in count:\n",
    "                count[(tail, -relation - 1)] = start\n",
    "            else:\n",
    "                count[(tail, -relation - 1)] += 1\n",
    "        return count\n",
    "\n",
    "    @staticmethod\n",
    "    def get_true_head_and_tail(triples):\n",
    "        '''\n",
    "        Build a dictionary of true triples that will\n",
    "        be used to filter these true triples for negative sampling\n",
    "        '''\n",
    "\n",
    "        true_head = {}\n",
    "        true_tail = {}\n",
    "\n",
    "        for head, relation, tail in triples:\n",
    "            if (head, relation) not in true_tail:\n",
    "                true_tail[(head, relation)] = []\n",
    "            true_tail[(head, relation)].append(tail)\n",
    "            if (relation, tail) not in true_head:\n",
    "                true_head[(relation, tail)] = []\n",
    "            true_head[(relation, tail)].append(head)\n",
    "\n",
    "        for relation, tail in true_head:\n",
    "            true_head[(relation, tail)] = np.array(list(set(true_head[(relation, tail)])))\n",
    "        for head, relation in true_tail:\n",
    "            true_tail[(head, relation)] = np.array(list(set(true_tail[(head, relation)])))\n",
    "\n",
    "        return true_head, true_tail\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, triples, all_true_triples, nentity, nrelation, mode):\n",
    "        self.len = len(triples)\n",
    "        self.triple_set = set(all_true_triples)\n",
    "        self.triples = triples\n",
    "        self.nentity = nentity\n",
    "        self.nrelation = nrelation\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        head, relation, tail = self.triples[idx]\n",
    "\n",
    "        if self.mode == 'head-batch':\n",
    "            tmp = [(0, rand_head) if (rand_head, relation, tail) not in self.triple_set\n",
    "                   else (-1, head) for rand_head in range(self.nentity)]\n",
    "            tmp[head] = (0, head)\n",
    "        elif self.mode == 'tail-batch':\n",
    "            tmp = [(0, rand_tail) if (head, relation, rand_tail) not in self.triple_set\n",
    "                   else (-1, tail) for rand_tail in range(self.nentity)]\n",
    "            tmp[tail] = (0, tail)\n",
    "        else:\n",
    "            raise ValueError('negative batch mode %s not supported' % self.mode)\n",
    "\n",
    "        tmp = torch.LongTensor(tmp)\n",
    "        filter_bias = tmp[:, 0].float()\n",
    "        negative_sample = tmp[:, 1]\n",
    "\n",
    "        positive_sample = torch.LongTensor((head, relation, tail))\n",
    "\n",
    "        return positive_sample, negative_sample, filter_bias, self.mode\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(data):\n",
    "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
    "        negative_sample = torch.stack([_[1] for _ in data], dim=0)\n",
    "        filter_bias = torch.stack([_[2] for _ in data], dim=0)\n",
    "        mode = data[0][3]\n",
    "        return positive_sample, negative_sample, filter_bias, mode\n",
    "\n",
    "\n",
    "class BidirectionalOneShotIterator(object):\n",
    "    def __init__(self, dataloader_head, dataloader_tail):\n",
    "        self.iterator_head = self.one_shot_iterator(dataloader_head)\n",
    "        self.iterator_tail = self.one_shot_iterator(dataloader_tail)\n",
    "        self.step = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        self.step += 1\n",
    "        if self.step % 2 == 0:\n",
    "            data = next(self.iterator_head)\n",
    "        else:\n",
    "            data = next(self.iterator_tail)\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def one_shot_iterator(dataloader):\n",
    "        '''\n",
    "        Transform a PyTorch Dataloader into python iterator\n",
    "        '''\n",
    "        while True:\n",
    "            for data in dataloader:\n",
    "                yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5f1e6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0dddd25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class KGEModel(nn.Module):\n",
    "    def __init__(self, model_name, nentity, nrelation, hidden_dim, gamma,\n",
    "                 double_entity_embedding=False, double_relation_embedding=False):\n",
    "        super(KGEModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.nentity = nentity\n",
    "        self.nrelation = nrelation\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.epsilon = 2.0\n",
    "\n",
    "        self.gamma = nn.Parameter(\n",
    "            torch.Tensor([gamma]),\n",
    "            requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.embedding_range = nn.Parameter(\n",
    "            torch.Tensor([(self.gamma.item() + self.epsilon) / hidden_dim]),\n",
    "            requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.entity_dim = hidden_dim * 2 if double_entity_embedding else hidden_dim\n",
    "        self.relation_dim = hidden_dim * 2 if double_relation_embedding else hidden_dim\n",
    "\n",
    "        self.entity_embedding = nn.Parameter(torch.zeros(nentity, self.entity_dim))\n",
    "        nn.init.uniform_(\n",
    "            tensor=self.entity_embedding,\n",
    "            a=-self.embedding_range.item(),\n",
    "            b=self.embedding_range.item()\n",
    "        )\n",
    "\n",
    "        self.relation_embedding = nn.Parameter(torch.zeros(nrelation, self.relation_dim))\n",
    "        nn.init.uniform_(\n",
    "            tensor=self.relation_embedding,\n",
    "            a=-self.embedding_range.item(),\n",
    "            b=self.embedding_range.item()\n",
    "        )\n",
    "\n",
    "        if model_name == 'pRotatE':\n",
    "            self.modulus = nn.Parameter(torch.Tensor([[0.5 * self.embedding_range.item()]]))\n",
    "\n",
    "        # Do not forget to modify this line when you add a new model in the \"forward\" function\n",
    "        if model_name not in ['TransE', 'DistMult', 'ComplEx', 'RotatE', 'pRotatE']:\n",
    "            raise ValueError('model %s not supported' % model_name)\n",
    "\n",
    "        if model_name == 'RotatE' and (not double_entity_embedding or double_relation_embedding):\n",
    "            raise ValueError('RotatE should use --double_entity_embedding')\n",
    "\n",
    "        if model_name == 'ComplEx' and (not double_entity_embedding or not double_relation_embedding):\n",
    "            raise ValueError('ComplEx should use --double_entity_embedding and --double_relation_embedding')\n",
    "\n",
    "    def forward(self, sample, mode='single'):\n",
    "        '''\n",
    "        Forward function that calculate the score of a batch of triples.\n",
    "        In the 'single' mode, sample is a batch of triple.\n",
    "        In the 'head-batch' or 'tail-batch' mode, sample consists two part.\n",
    "        The first part is usually the positive sample.\n",
    "        And the second part is the entities in the negative samples.\n",
    "        Because negative samples and positive samples usually share two elements\n",
    "        in their triple ((head, relation) or (relation, tail)).\n",
    "        '''\n",
    "\n",
    "        if mode == 'single':\n",
    "            batch_size, negative_sample_size = sample.size(0), 1\n",
    "\n",
    "            head = torch.index_select(\n",
    "                self.entity_embedding,\n",
    "                dim=0,\n",
    "                index=sample[:, 0]\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "            relation = torch.index_select(\n",
    "                self.relation_embedding,\n",
    "                dim=0,\n",
    "                index=sample[:, 1]\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "            try:\n",
    "                tail = torch.index_select(\n",
    "                    self.entity_embedding,\n",
    "                    dim=0,\n",
    "                    index=sample[:, 2]\n",
    "                ).unsqueeze(1)\n",
    "            except IndexError:\n",
    "                print(sample)\n",
    "        elif mode == 'head-batch':\n",
    "            tail_part, head_part = sample\n",
    "            batch_size, negative_sample_size = head_part.size(0), head_part.size(1)\n",
    "\n",
    "            head = torch.index_select(\n",
    "                self.entity_embedding,\n",
    "                dim=0,\n",
    "                index=head_part.view(-1)\n",
    "            ).view(batch_size, negative_sample_size, -1)\n",
    "\n",
    "            relation = torch.index_select(\n",
    "                self.relation_embedding,\n",
    "                dim=0,\n",
    "                index=tail_part[:, 1]\n",
    "            ).unsqueeze(1)\n",
    "            try:\n",
    "                tail = torch.index_select(\n",
    "                    self.entity_embedding,\n",
    "                    dim=0,\n",
    "                    index=tail_part[:, 2]\n",
    "                ).unsqueeze(1)\n",
    "            except IndexError:\n",
    "                print(tail_part)\n",
    "\n",
    "        elif mode == 'tail-batch':\n",
    "            head_part, tail_part = sample\n",
    "            batch_size, negative_sample_size = tail_part.size(0), tail_part.size(1)\n",
    "\n",
    "            head = torch.index_select(\n",
    "                self.entity_embedding,\n",
    "                dim=0,\n",
    "                index=head_part[:, 0]\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "            relation = torch.index_select(\n",
    "                self.relation_embedding,\n",
    "                dim=0,\n",
    "                index=head_part[:, 1]\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "            tail = torch.index_select(\n",
    "                self.entity_embedding,\n",
    "                dim=0,\n",
    "                index=tail_part.view(-1)\n",
    "            ).view(batch_size, negative_sample_size, -1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('mode %s not supported' % mode)\n",
    "\n",
    "        model_func = {\n",
    "            'TransE': self.TransE,\n",
    "            'DistMult': self.DistMult,\n",
    "            'ComplEx': self.ComplEx,\n",
    "            'RotatE': self.RotatE,\n",
    "            'pRotatE': self.pRotatE\n",
    "        }\n",
    "\n",
    "        if self.model_name in model_func:\n",
    "            score = model_func[self.model_name](head, relation, tail, mode)\n",
    "        else:\n",
    "            raise ValueError('model %s not supported' % self.model_name)\n",
    "\n",
    "        print(f'Score {mode}: {score}')\n",
    "        return score\n",
    "\n",
    "    def TransE(self, head, relation, tail, mode):\n",
    "\n",
    "        if mode == 'head-batch':\n",
    "            score = head + (relation - tail)\n",
    "        else:\n",
    "            score = (head + relation) - tail\n",
    "\n",
    "        score = self.gamma.item() - torch.norm(score, p=1, dim=2)\n",
    "        return score\n",
    "\n",
    "    def DistMult(self, head, relation, tail, mode):\n",
    "        if mode == 'head-batch':\n",
    "            score = head * (relation * tail)\n",
    "        else:\n",
    "            score = (head * relation) * tail\n",
    "\n",
    "        score = score.sum(dim=2)\n",
    "        return score\n",
    "\n",
    "    def ComplEx(self, head, relation, tail, mode):\n",
    "        re_head, im_head = torch.chunk(head, 2, dim=2)\n",
    "        re_relation, im_relation = torch.chunk(relation, 2, dim=2)\n",
    "        re_tail, im_tail = torch.chunk(tail, 2, dim=2)\n",
    "\n",
    "        if mode == 'head-batch':\n",
    "            re_score = re_relation * re_tail + im_relation * im_tail\n",
    "            im_score = re_relation * im_tail - im_relation * re_tail\n",
    "            score = re_head * re_score + im_head * im_score\n",
    "        else:\n",
    "            re_score = re_head * re_relation - im_head * im_relation\n",
    "            im_score = re_head * im_relation + im_head * re_relation\n",
    "            score = re_score * re_tail + im_score * im_tail\n",
    "\n",
    "        score = score.sum(dim=2)\n",
    "        return score\n",
    "\n",
    "    def RotatE(self, head, relation, tail, mode):\n",
    "        pi = 3.14159265358979323846\n",
    "\n",
    "        re_head, im_head = torch.chunk(head, 2, dim=2)\n",
    "        re_tail, im_tail = torch.chunk(tail, 2, dim=2)\n",
    "\n",
    "        # Make phases of relations uniformly distributed in [-pi, pi]\n",
    "\n",
    "        phase_relation = relation / (self.embedding_range.item() / pi)\n",
    "\n",
    "        re_relation = torch.cos(phase_relation)\n",
    "        im_relation = torch.sin(phase_relation)\n",
    "\n",
    "        if mode == 'head-batch':\n",
    "            re_score = re_relation * re_tail + im_relation * im_tail\n",
    "            im_score = re_relation * im_tail - im_relation * re_tail\n",
    "            re_score = re_score - re_head\n",
    "            im_score = im_score - im_head\n",
    "        else:\n",
    "            re_score = re_head * re_relation - im_head * im_relation\n",
    "            im_score = re_head * im_relation + im_head * re_relation\n",
    "            re_score = re_score - re_tail\n",
    "            im_score = im_score - im_tail\n",
    "\n",
    "        score = torch.stack([re_score, im_score], dim=0)\n",
    "        score = score.norm(dim=0)\n",
    "\n",
    "        score = self.gamma.item() - score.sum(dim=2)\n",
    "        return score\n",
    "\n",
    "    def pRotatE(self, head, relation, tail, mode):\n",
    "        pi = 3.14159262358979323846\n",
    "\n",
    "        # Make phases of entities and relations uniformly distributed in [-pi, pi]\n",
    "\n",
    "        phase_head = head / (self.embedding_range.item() / pi)\n",
    "        phase_relation = relation / (self.embedding_range.item() / pi)\n",
    "        phase_tail = tail / (self.embedding_range.item() / pi)\n",
    "\n",
    "        if mode == 'head-batch':\n",
    "            score = phase_head + (phase_relation - phase_tail)\n",
    "        else:\n",
    "            score = (phase_head + phase_relation) - phase_tail\n",
    "\n",
    "        score = torch.sin(score)\n",
    "        score = torch.abs(score)\n",
    "\n",
    "        score = self.gamma.item() - score.sum(dim=2) * self.modulus\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def train_step(model, optimizer, train_iterator, args):\n",
    "        '''\n",
    "        A single train step. Apply back-propation and return the loss\n",
    "        '''\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        positive_sample, negative_sample, subsampling_weight, mode = next(train_iterator)\n",
    "\n",
    "        if args.cuda:\n",
    "            positive_sample = positive_sample.cuda()\n",
    "            negative_sample = negative_sample.cuda()\n",
    "            subsampling_weight = subsampling_weight.cuda()\n",
    "\n",
    "        negative_score = model((positive_sample, negative_sample), mode=mode)\n",
    "\n",
    "        if args.negative_adversarial_sampling:\n",
    "            # In self-adversarial sampling, we do not apply back-propagation on the sampling weight\n",
    "            negative_score = (F.softmax(negative_score * args.adversarial_temperature, dim=1).detach()\n",
    "                              * F.logsigmoid(-negative_score)).sum(dim=1)\n",
    "        else:\n",
    "            negative_score = F.logsigmoid(-negative_score).mean(dim=1)\n",
    "\n",
    "        positive_score = model(positive_sample)\n",
    "\n",
    "        positive_score = F.logsigmoid(positive_score).squeeze(dim=1)\n",
    "\n",
    "        if args.uni_weight:\n",
    "            positive_sample_loss = - positive_score.mean()\n",
    "            negative_sample_loss = - negative_score.mean()\n",
    "        else:\n",
    "            positive_sample_loss = - (subsampling_weight * positive_score).sum() / subsampling_weight.sum()\n",
    "            negative_sample_loss = - (subsampling_weight * negative_score).sum() / subsampling_weight.sum()\n",
    "\n",
    "        loss = (positive_sample_loss + negative_sample_loss) / 2\n",
    "\n",
    "        if args.regularization != 0.0:\n",
    "            # Use L3 regularization for ComplEx and DistMult\n",
    "            regularization = args.regularization * (\n",
    "                    model.entity_embedding.norm(p=3) ** 3 +\n",
    "                    model.relation_embedding.norm(p=3).norm(p=3) ** 3\n",
    "            )\n",
    "            loss = loss + regularization\n",
    "            regularization_log = {'regularization': regularization.item()}\n",
    "        else:\n",
    "            regularization_log = {}\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Positive sample loss: {positive_sample_loss.item()}\\nNegative sample loss: {negative_sample_loss.item()}\\nTotal loss: {loss.item()}')\n",
    "        \n",
    "        loss_values = {\n",
    "            **regularization_log,\n",
    "            'pos_sample_loss': positive_sample_loss.item(),\n",
    "            'neg_sample_loss': negative_sample_loss.item(),\n",
    "            'loss': loss.item()\n",
    "        }\n",
    "\n",
    "        return loss_values\n",
    "\n",
    "    @staticmethod\n",
    "    def test_step(model, test_triples, all_true_triples, args):\n",
    "        '''\n",
    "        Evaluate the model on test or valid datasets\n",
    "        '''\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Otherwise use standard (filtered) MRR, MR, HITS@1, HITS@3, and HITS@10 metrics\n",
    "        # Prepare dataloader for evaluation\n",
    "        test_dataloader_head = DataLoader(\n",
    "            TestDataset(\n",
    "                test_triples,\n",
    "                all_true_triples,\n",
    "                args.nentity,\n",
    "                args.nrelation,\n",
    "                'head-batch'\n",
    "            ),\n",
    "            batch_size=args.test_batch_size,\n",
    "            num_workers=max(1, args.cpu_num // 2),\n",
    "            collate_fn=TestDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        test_dataloader_tail = DataLoader(\n",
    "            TestDataset(\n",
    "                test_triples,\n",
    "                all_true_triples,\n",
    "                args.nentity,\n",
    "                args.nrelation,\n",
    "                'tail-batch'\n",
    "            ),\n",
    "            batch_size=args.test_batch_size,\n",
    "            num_workers=max(1, args.cpu_num // 2),\n",
    "            collate_fn=TestDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        test_dataset_list = [test_dataloader_head, test_dataloader_tail]\n",
    "\n",
    "        logs = []\n",
    "\n",
    "        step = 0\n",
    "        total_steps = sum([len(dataset) for dataset in test_dataset_list])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_dataset in test_dataset_list:\n",
    "                for positive_sample, negative_sample, filter_bias, mode in test_dataset:\n",
    "                    if args.cuda:\n",
    "                        positive_sample = positive_sample.cuda()\n",
    "                        negative_sample = negative_sample.cuda()\n",
    "                        filter_bias = filter_bias.cuda()\n",
    "\n",
    "                    batch_size = positive_sample.size(0)\n",
    "\n",
    "                    score = model((positive_sample, negative_sample), mode)\n",
    "                    score += filter_bias\n",
    "\n",
    "                    # Explicitly sort all the entities to ensure that there is no test exposure bias\n",
    "                    argsort = torch.argsort(score, dim=1, descending=True)\n",
    "\n",
    "                    if mode == 'head-batch':\n",
    "                        positive_arg = positive_sample[:, 0]\n",
    "                    elif mode == 'tail-batch':\n",
    "                        positive_arg = positive_sample[:, 2]\n",
    "                    else:\n",
    "                        raise ValueError('mode %s not supported' % mode)\n",
    "\n",
    "                    for i in range(batch_size):\n",
    "                        # Notice that argsort is not ranking\n",
    "                        ranking = (argsort[i, :] == positive_arg[i]).nonzero()\n",
    "                        assert ranking.size(0) == 1\n",
    "\n",
    "                        # ranking + 1 is the true ranking used in evaluation metrics\n",
    "                        ranking = 1 + ranking.item()\n",
    "                        logs.append({\n",
    "                            'MRR': 1.0 / ranking,\n",
    "                            'MR': float(ranking),\n",
    "                            'HITS@1': 1.0 if ranking <= 1 else 0.0,\n",
    "                            'HITS@3': 1.0 if ranking <= 3 else 0.0,\n",
    "                            'HITS@10': 1.0 if ranking <= 10 else 0.0,\n",
    "                        })\n",
    "\n",
    "                    if step % args.test_log_steps == 0:\n",
    "                        logging.info('Evaluating the model... (%d/%d)' % (step, total_steps))\n",
    "\n",
    "                    step += 1\n",
    "\n",
    "        metrics = {}\n",
    "        for metric in logs[0].keys():\n",
    "            metrics[metric] = sum([log[metric] for log in logs]) / len(logs)\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65fe0f",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e8efe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "\n",
    "\n",
    "\n",
    "def readTxt(file_name):\n",
    "    class_list = list()\n",
    "    wnids = open(file_name, 'rU')\n",
    "    try:\n",
    "        for line in wnids:\n",
    "            line = line[:-1]\n",
    "            class_list.append(line)\n",
    "    finally:\n",
    "        wnids.close()\n",
    "    print(len(class_list))\n",
    "    return class_list\n",
    "\n",
    "def load_class():\n",
    "    seen = readTxt(seen_file)\n",
    "    unseen = readTxt(unseen_file)\n",
    "    return seen, unseen\n",
    "\n",
    "###########################\n",
    "\n",
    "def loadDict(file_name):\n",
    "    entities = list()\n",
    "    wnids = open(file_name, 'rU')\n",
    "    try:\n",
    "        for line in wnids:\n",
    "            line = line[:-1]\n",
    "            index, cls = line.split('\\t')\n",
    "            entities.append(cls)\n",
    "    finally:\n",
    "        wnids.close()\n",
    "    print(len(entities))\n",
    "    return entities\n",
    "\n",
    "\n",
    "def save_embed_awa(filename, wnids, names):\n",
    "\n",
    "    # load embeddings\n",
    "    embeds = np.load(filename)\n",
    "    # save to .mat file\n",
    "    matcontent = scio.loadmat(os.path.join(DATASET_DIR, 'att_splits.mat'))\n",
    "    all_names = matcontent['allclasses_names'].squeeze().tolist()\n",
    "\n",
    "    embed_size = embeds.shape[1]\n",
    "    o2v = np.zeros((len(all_names), embed_size), dtype=np.float)\n",
    "    for i in range(len(all_names)):\n",
    "        name = all_names[i][0]\n",
    "        wnid = wnids[names.index(name)]\n",
    "        o2v[i] = embeds[entities.index(wnid)]\n",
    "\n",
    "    print(o2v.shape)\n",
    "\n",
    "    o2v_file = os.path.join(DATA_DIR, save_file)\n",
    "    scio.savemat(o2v_file, {'o2v': o2v})\n",
    "\n",
    "def save_embed(filename, classes):\n",
    "\n",
    "    # load embeddings\n",
    "    embeds = np.load(filename)\n",
    "    # save to .mat file\n",
    "    matcontent = scio.loadmat(os.path.join(datadir, 'ImageNet', 'w2v.mat'))\n",
    "    wnids = matcontent['wnids'].squeeze().tolist()\n",
    "    wnids = wnids[:2549]\n",
    "    embed_size = embeds.shape[1]\n",
    "    o2v = np.zeros((len(wnids), embed_size), dtype=np.float)\n",
    "\n",
    "    print(o2v.shape)\n",
    "    for i, wnid in enumerate(wnids):\n",
    "        wnid = wnid[0]\n",
    "        if wnid in classes:\n",
    "            o2v[i] = embeds[entities.index(wnid)]\n",
    "        else:\n",
    "            continue\n",
    "    # save wnids together\n",
    "    wnids_cell = np.empty((len(wnids), 1), dtype=np.object)\n",
    "    for i in range(len(wnids)):\n",
    "        wnids_cell[i][0] = np.array(wnids[i])\n",
    "\n",
    "    o2v_file = os.path.join(DATA_DIR, save_file)\n",
    "    scio.savemat(o2v_file, {'o2v': o2v, 'wnids': wnids_cell})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8042697",
   "metadata": {},
   "source": [
    "### Training the model for the structural embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741a965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: TransE\n",
      "#entity num: 124749\n",
      "#relation num: 5\n",
      "#total triples num: 573708\n",
      "Ramdomly Initializing TransE Model...\n",
      "------ Start Training...\n",
      "batch_size = 256\n",
      "negative sample size = 1024\n",
      "hidden_dim = 100\n",
      "gamma = 12.000000\n",
      "negative_adversarial_sampling = True\n",
      "adversarial_temperature = 1.000000\n",
      "learning rate = 0.000050\n",
      "Score tail-batch: tensor([[ 0.9952,  1.3985,  0.0675,  ..., -0.1166,  1.0939,  0.1181],\n",
      "        [ 0.4407,  0.2726,  0.2590,  ...,  2.2461,  0.7529, -0.2127],\n",
      "        [-0.5408,  0.5837,  0.2830,  ...,  1.5794,  0.8832,  1.5062],\n",
      "        ...,\n",
      "        [ 2.4926,  0.0917,  0.1812,  ...,  1.1921,  0.5162,  0.3459],\n",
      "        [ 0.5466,  1.3118,  0.3757,  ...,  0.6017,  0.9507,  1.3867],\n",
      "        [ 1.4837,  0.2415,  1.9275,  ..., -0.0282,  0.5110,  1.5777]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[ 0.3414],\n",
      "        [ 0.6608],\n",
      "        [ 1.5780],\n",
      "        [ 0.2772],\n",
      "        [ 1.0271],\n",
      "        [ 0.4631],\n",
      "        [ 1.1198],\n",
      "        [ 1.6181],\n",
      "        [ 0.5737],\n",
      "        [-0.0098],\n",
      "        [ 0.1787],\n",
      "        [ 0.1012],\n",
      "        [ 1.3943],\n",
      "        [ 0.4520],\n",
      "        [ 0.2408],\n",
      "        [-0.3113],\n",
      "        [ 0.9970],\n",
      "        [ 0.2069],\n",
      "        [ 1.0021],\n",
      "        [ 0.9978],\n",
      "        [-0.0215],\n",
      "        [ 1.3952],\n",
      "        [-0.3144],\n",
      "        [ 1.1804],\n",
      "        [ 0.6674],\n",
      "        [ 0.9071],\n",
      "        [-0.9189],\n",
      "        [ 0.4005],\n",
      "        [ 1.0475],\n",
      "        [ 0.2730],\n",
      "        [ 0.9539],\n",
      "        [ 0.9742],\n",
      "        [ 1.0706],\n",
      "        [ 0.0317],\n",
      "        [ 1.8447],\n",
      "        [ 0.4787],\n",
      "        [ 1.1625],\n",
      "        [ 0.9796],\n",
      "        [ 0.4176],\n",
      "        [ 0.3899],\n",
      "        [-0.4488],\n",
      "        [ 0.3037],\n",
      "        [-0.7350],\n",
      "        [-0.2084],\n",
      "        [ 0.9210],\n",
      "        [ 0.6386],\n",
      "        [ 1.0714],\n",
      "        [ 0.1680],\n",
      "        [ 0.7691],\n",
      "        [ 1.8576],\n",
      "        [ 0.5375],\n",
      "        [ 0.2105],\n",
      "        [-0.5152],\n",
      "        [ 0.3133],\n",
      "        [ 1.9970],\n",
      "        [ 1.0023],\n",
      "        [ 1.0803],\n",
      "        [ 0.4368],\n",
      "        [ 0.2814],\n",
      "        [ 0.3672],\n",
      "        [ 0.6541],\n",
      "        [ 0.1182],\n",
      "        [ 1.0066],\n",
      "        [ 0.9044],\n",
      "        [-0.2949],\n",
      "        [ 0.9623],\n",
      "        [ 0.6005],\n",
      "        [ 1.5624],\n",
      "        [ 0.7031],\n",
      "        [ 1.2321],\n",
      "        [ 0.2826],\n",
      "        [-0.6597],\n",
      "        [ 0.8215],\n",
      "        [ 0.1467],\n",
      "        [ 0.9030],\n",
      "        [ 0.1378],\n",
      "        [ 0.6311],\n",
      "        [ 0.6604],\n",
      "        [ 1.1783],\n",
      "        [-0.4616],\n",
      "        [ 1.8640],\n",
      "        [ 0.0775],\n",
      "        [-0.1899],\n",
      "        [ 0.4629],\n",
      "        [ 0.8157],\n",
      "        [ 0.5119],\n",
      "        [ 0.2096],\n",
      "        [ 0.1370],\n",
      "        [ 1.2308],\n",
      "        [ 0.7947],\n",
      "        [ 1.3823],\n",
      "        [ 1.0188],\n",
      "        [ 0.3990],\n",
      "        [ 0.0492],\n",
      "        [ 0.2234],\n",
      "        [ 0.1326],\n",
      "        [ 0.7759],\n",
      "        [-0.3334],\n",
      "        [ 0.5427],\n",
      "        [ 1.3030],\n",
      "        [ 1.0966],\n",
      "        [-0.3446],\n",
      "        [-0.3504],\n",
      "        [-0.2794],\n",
      "        [ 0.0948],\n",
      "        [ 0.5070],\n",
      "        [ 1.6636],\n",
      "        [ 1.0105],\n",
      "        [ 0.1603],\n",
      "        [ 1.9722],\n",
      "        [-1.4313],\n",
      "        [ 0.7204],\n",
      "        [ 0.2185],\n",
      "        [ 0.7856],\n",
      "        [-0.1556],\n",
      "        [ 0.0769],\n",
      "        [-0.5449],\n",
      "        [ 0.0496],\n",
      "        [-0.6223],\n",
      "        [ 0.6995],\n",
      "        [-0.4529],\n",
      "        [ 0.5894],\n",
      "        [ 0.5408],\n",
      "        [ 2.1625],\n",
      "        [-0.1477],\n",
      "        [ 0.8798],\n",
      "        [ 0.0855],\n",
      "        [-0.3193],\n",
      "        [ 0.1768],\n",
      "        [ 1.3946],\n",
      "        [ 0.7133],\n",
      "        [ 1.1492],\n",
      "        [ 0.7536],\n",
      "        [ 1.0728],\n",
      "        [ 0.1176],\n",
      "        [-0.3973],\n",
      "        [ 1.3373],\n",
      "        [ 1.3722],\n",
      "        [ 1.5944],\n",
      "        [ 1.5081],\n",
      "        [ 0.0428],\n",
      "        [ 1.3081],\n",
      "        [ 1.5757],\n",
      "        [ 0.8517],\n",
      "        [-0.1161],\n",
      "        [ 1.3594],\n",
      "        [ 0.3678],\n",
      "        [ 0.8738],\n",
      "        [ 0.2883],\n",
      "        [-0.5680],\n",
      "        [-1.1523],\n",
      "        [ 1.3561],\n",
      "        [ 2.9017],\n",
      "        [ 1.1500],\n",
      "        [ 1.2182],\n",
      "        [ 1.8732],\n",
      "        [ 0.8706],\n",
      "        [-0.4544],\n",
      "        [-0.4078],\n",
      "        [ 0.7668],\n",
      "        [ 0.2892],\n",
      "        [ 0.7545],\n",
      "        [ 1.3315],\n",
      "        [ 1.2099],\n",
      "        [ 0.2220],\n",
      "        [ 1.5788],\n",
      "        [ 0.7571],\n",
      "        [ 0.9152],\n",
      "        [ 0.2704],\n",
      "        [ 0.3592],\n",
      "        [ 0.2241],\n",
      "        [ 0.3207],\n",
      "        [-0.6491],\n",
      "        [ 1.2561],\n",
      "        [ 1.9252],\n",
      "        [ 0.8182],\n",
      "        [-0.6407],\n",
      "        [ 1.3539],\n",
      "        [ 0.7858],\n",
      "        [ 0.5182],\n",
      "        [ 0.9761],\n",
      "        [-0.1465],\n",
      "        [ 1.6150],\n",
      "        [ 0.8247],\n",
      "        [ 0.2865],\n",
      "        [ 0.9949],\n",
      "        [ 0.9364],\n",
      "        [ 0.8930],\n",
      "        [-0.0905],\n",
      "        [ 1.3092],\n",
      "        [ 0.5588],\n",
      "        [ 0.7195],\n",
      "        [-0.0837],\n",
      "        [ 0.6906],\n",
      "        [-0.6028],\n",
      "        [ 0.9401],\n",
      "        [ 1.2136],\n",
      "        [ 0.5998],\n",
      "        [ 1.5655],\n",
      "        [-0.0282],\n",
      "        [ 0.9794],\n",
      "        [ 1.9623],\n",
      "        [ 0.7773],\n",
      "        [-0.5528],\n",
      "        [-1.1175],\n",
      "        [-0.3846],\n",
      "        [ 0.2457],\n",
      "        [ 1.1334],\n",
      "        [ 0.4669],\n",
      "        [-0.2767],\n",
      "        [-0.2538],\n",
      "        [ 0.4039],\n",
      "        [-0.1036],\n",
      "        [ 1.0137],\n",
      "        [ 1.0049],\n",
      "        [ 0.3412],\n",
      "        [ 1.0641],\n",
      "        [ 0.8557],\n",
      "        [ 0.0803],\n",
      "        [-0.1773],\n",
      "        [ 1.3658],\n",
      "        [ 0.5191],\n",
      "        [ 0.0828],\n",
      "        [ 1.2842],\n",
      "        [ 0.6336],\n",
      "        [-0.6277],\n",
      "        [ 1.5992],\n",
      "        [ 0.6485],\n",
      "        [ 1.9661],\n",
      "        [ 0.7038],\n",
      "        [ 0.6495],\n",
      "        [ 0.9808],\n",
      "        [ 1.5988],\n",
      "        [ 1.6870],\n",
      "        [ 1.3560],\n",
      "        [ 1.9977],\n",
      "        [ 0.4987],\n",
      "        [-0.8098],\n",
      "        [ 0.5796],\n",
      "        [-0.5277],\n",
      "        [-0.8773],\n",
      "        [ 0.7902],\n",
      "        [ 0.7547],\n",
      "        [ 0.2866],\n",
      "        [-0.2937],\n",
      "        [ 1.4786],\n",
      "        [ 1.4564],\n",
      "        [-0.2912],\n",
      "        [ 1.2536],\n",
      "        [-0.1297],\n",
      "        [ 1.3146],\n",
      "        [-0.1409],\n",
      "        [ 0.4476],\n",
      "        [ 0.6268],\n",
      "        [ 0.2215],\n",
      "        [ 1.4308]], grad_fn=<RsubBackward1>)\n",
      "Positive sample loss: 0.43685299158096313\n",
      "Negative sample loss: 1.4411927461624146\n",
      "Total loss: 0.9390228986740112\n",
      "Score head-batch: tensor([[ 0.0513,  0.6638,  1.4766,  ...,  2.8286,  0.8030,  0.9630],\n",
      "        [ 0.6431,  1.4357,  0.4413,  ...,  0.2889,  0.0273,  0.6189],\n",
      "        [ 1.3854,  0.1333, -0.1888,  ...,  0.4936,  0.0719,  0.4075],\n",
      "        ...,\n",
      "        [ 1.4669,  0.1469,  0.2852,  ...,  0.0576,  0.7432,  0.7355],\n",
      "        [-0.0075,  0.9536,  0.2571,  ...,  0.9576,  1.4810,  0.9826],\n",
      "        [-0.2387, -1.0773, -0.2334,  ...,  0.3692,  1.1750, -0.3133]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[ 0.3194],\n",
      "        [ 1.1819],\n",
      "        [ 0.2465],\n",
      "        [ 0.3597],\n",
      "        [ 1.0125],\n",
      "        [ 1.0176],\n",
      "        [ 1.1423],\n",
      "        [ 0.7358],\n",
      "        [ 1.7587],\n",
      "        [-0.5240],\n",
      "        [-0.8248],\n",
      "        [ 0.4758],\n",
      "        [ 0.5811],\n",
      "        [ 0.8674],\n",
      "        [ 1.2622],\n",
      "        [ 0.7042],\n",
      "        [ 0.2929],\n",
      "        [ 0.8592],\n",
      "        [ 0.7795],\n",
      "        [ 0.8630],\n",
      "        [-0.5868],\n",
      "        [ 1.5263],\n",
      "        [ 0.0862],\n",
      "        [-0.0565],\n",
      "        [ 0.4407],\n",
      "        [ 0.8638],\n",
      "        [ 2.4556],\n",
      "        [ 0.4333],\n",
      "        [ 0.6118],\n",
      "        [ 1.0599],\n",
      "        [-0.6746],\n",
      "        [ 1.7078],\n",
      "        [ 2.3834],\n",
      "        [ 0.5392],\n",
      "        [ 1.2308],\n",
      "        [ 0.1086],\n",
      "        [ 1.1434],\n",
      "        [ 0.6566],\n",
      "        [ 0.3398],\n",
      "        [ 1.9512],\n",
      "        [ 0.5571],\n",
      "        [ 0.8809],\n",
      "        [-0.0308],\n",
      "        [ 1.8067],\n",
      "        [ 1.7065],\n",
      "        [ 1.3328],\n",
      "        [ 0.2296],\n",
      "        [ 0.1096],\n",
      "        [ 0.5416],\n",
      "        [ 0.5087],\n",
      "        [-0.6500],\n",
      "        [ 1.0906],\n",
      "        [-0.0981],\n",
      "        [ 0.2716],\n",
      "        [ 1.6230],\n",
      "        [ 1.1864],\n",
      "        [ 0.5815],\n",
      "        [ 1.2937],\n",
      "        [-0.0307],\n",
      "        [ 1.6654],\n",
      "        [ 0.1850],\n",
      "        [ 0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 0.5091],\n",
      "        [ 2.0585],\n",
      "        [ 1.8748],\n",
      "        [-0.4954],\n",
      "        [ 0.8940],\n",
      "        [ 0.5768],\n",
      "        [ 0.5367],\n",
      "        [ 1.2538],\n",
      "        [ 1.0504],\n",
      "        [ 0.5544],\n",
      "        [ 0.8611],\n",
      "        [ 0.6494],\n",
      "        [-0.7424],\n",
      "        [ 1.5278],\n",
      "        [ 2.5820],\n",
      "        [ 1.7414],\n",
      "        [ 0.0066],\n",
      "        [ 0.4144],\n",
      "        [-0.6146],\n",
      "        [-0.1439],\n",
      "        [ 1.5645],\n",
      "        [ 0.6517],\n",
      "        [ 0.7443],\n",
      "        [ 0.7996],\n",
      "        [ 0.5585],\n",
      "        [ 1.0804],\n",
      "        [-0.1724],\n",
      "        [ 0.3407],\n",
      "        [ 0.0833],\n",
      "        [ 0.0604],\n",
      "        [ 0.3149],\n",
      "        [ 1.5188],\n",
      "        [ 0.4583],\n",
      "        [ 0.7706],\n",
      "        [ 0.6930],\n",
      "        [-0.2341],\n",
      "        [ 1.1912],\n",
      "        [ 1.2384],\n",
      "        [ 0.2987],\n",
      "        [-0.4898],\n",
      "        [ 1.6047],\n",
      "        [ 0.0663],\n",
      "        [ 0.0535],\n",
      "        [ 0.5226],\n",
      "        [-1.1347],\n",
      "        [ 0.3467],\n",
      "        [ 1.5371],\n",
      "        [ 0.9865],\n",
      "        [-0.0357],\n",
      "        [ 0.2419],\n",
      "        [ 1.6424],\n",
      "        [ 0.2925],\n",
      "        [-0.9146],\n",
      "        [ 1.8762],\n",
      "        [ 0.2642],\n",
      "        [ 0.1672],\n",
      "        [-0.3910],\n",
      "        [ 0.4712],\n",
      "        [-0.4764],\n",
      "        [ 2.0872],\n",
      "        [ 0.1350],\n",
      "        [ 2.4381],\n",
      "        [ 0.1554],\n",
      "        [ 0.3453],\n",
      "        [ 0.5968],\n",
      "        [ 0.1998],\n",
      "        [ 1.4216],\n",
      "        [ 0.0773],\n",
      "        [ 0.9334],\n",
      "        [ 0.1291],\n",
      "        [ 0.0990],\n",
      "        [-0.2153],\n",
      "        [ 1.4446],\n",
      "        [ 1.1963],\n",
      "        [ 1.8033],\n",
      "        [ 1.0132],\n",
      "        [ 0.9525],\n",
      "        [ 0.1497],\n",
      "        [-0.0063],\n",
      "        [ 0.1454],\n",
      "        [ 1.3132],\n",
      "        [ 0.4036],\n",
      "        [ 1.0376],\n",
      "        [ 0.0541],\n",
      "        [ 0.7495],\n",
      "        [ 0.5238],\n",
      "        [ 1.0453],\n",
      "        [ 1.0335],\n",
      "        [ 0.6488],\n",
      "        [ 0.8524],\n",
      "        [ 1.0287],\n",
      "        [ 0.0185],\n",
      "        [ 0.0103],\n",
      "        [ 2.5313],\n",
      "        [ 0.3766],\n",
      "        [-0.2213],\n",
      "        [ 1.1919],\n",
      "        [-0.4405],\n",
      "        [ 1.1844],\n",
      "        [ 0.5321],\n",
      "        [ 1.4632],\n",
      "        [-0.3324],\n",
      "        [ 0.9652],\n",
      "        [ 1.3664],\n",
      "        [ 0.9560],\n",
      "        [ 1.1338],\n",
      "        [ 0.8420],\n",
      "        [ 1.2092],\n",
      "        [ 1.1542],\n",
      "        [ 1.6976],\n",
      "        [ 0.8463],\n",
      "        [ 1.5566],\n",
      "        [ 0.5387],\n",
      "        [ 1.1207],\n",
      "        [ 0.7443],\n",
      "        [ 1.1701],\n",
      "        [ 1.1223],\n",
      "        [ 1.0331],\n",
      "        [ 1.2935],\n",
      "        [-0.2206],\n",
      "        [-0.6743],\n",
      "        [ 1.3540],\n",
      "        [ 0.6055],\n",
      "        [ 0.7382],\n",
      "        [ 0.0145],\n",
      "        [ 1.3756],\n",
      "        [-0.2876],\n",
      "        [ 2.5397],\n",
      "        [ 0.7582],\n",
      "        [-0.0472],\n",
      "        [ 0.5048],\n",
      "        [ 0.5009],\n",
      "        [ 1.2095],\n",
      "        [ 1.5860],\n",
      "        [ 0.3554],\n",
      "        [ 0.9536],\n",
      "        [ 1.0148],\n",
      "        [ 1.4205],\n",
      "        [ 1.4303],\n",
      "        [ 0.1093],\n",
      "        [ 0.9423],\n",
      "        [ 1.5136],\n",
      "        [ 1.1045],\n",
      "        [ 0.7017],\n",
      "        [ 0.1069],\n",
      "        [-0.2530],\n",
      "        [-1.1966],\n",
      "        [-0.6507],\n",
      "        [ 1.1034],\n",
      "        [ 1.1013],\n",
      "        [-0.1799],\n",
      "        [-0.6890],\n",
      "        [ 1.2925],\n",
      "        [ 0.1459],\n",
      "        [ 1.4087],\n",
      "        [ 0.4233],\n",
      "        [ 1.0260],\n",
      "        [ 1.4740],\n",
      "        [ 1.6094],\n",
      "        [ 1.7167],\n",
      "        [-0.0854],\n",
      "        [ 1.3800],\n",
      "        [-0.7878],\n",
      "        [ 0.9332],\n",
      "        [-0.5933],\n",
      "        [-0.4345],\n",
      "        [-0.4329],\n",
      "        [ 1.3051],\n",
      "        [ 1.0880],\n",
      "        [ 2.3128],\n",
      "        [-0.2221],\n",
      "        [ 1.3553],\n",
      "        [ 1.5956],\n",
      "        [ 0.9193],\n",
      "        [ 1.7421],\n",
      "        [-0.1410],\n",
      "        [-0.4276],\n",
      "        [ 0.3033],\n",
      "        [-0.7592],\n",
      "        [ 0.2007],\n",
      "        [ 0.8538],\n",
      "        [-0.0535],\n",
      "        [-0.8755],\n",
      "        [ 1.2060],\n",
      "        [ 0.5037],\n",
      "        [ 0.7272],\n",
      "        [ 0.5945],\n",
      "        [ 1.8551],\n",
      "        [ 0.6525],\n",
      "        [-0.0655],\n",
      "        [ 0.5838],\n",
      "        [-0.0898],\n",
      "        [ 0.3419]], grad_fn=<RsubBackward1>)\n",
      "Positive sample loss: 0.4366306960582733\n",
      "Negative sample loss: 1.4726369380950928\n",
      "Total loss: 0.9546338319778442\n",
      "Score tail-batch: tensor([[ 1.2637,  0.9921, -0.5154,  ...,  0.4340,  1.2988,  0.9421],\n",
      "        [ 2.2239,  1.8130,  2.2986,  ...,  0.8657,  0.9243,  1.3458],\n",
      "        [ 1.3724,  0.7827,  1.0032,  ...,  1.1792,  0.6570,  1.7030],\n",
      "        ...,\n",
      "        [ 0.0184,  1.2360,  1.9860,  ...,  0.7341,  0.5593,  0.8597],\n",
      "        [ 0.4750,  1.2250,  0.6242,  ...,  1.0797,  0.6649,  1.3699],\n",
      "        [ 0.4284, -0.0928,  1.5515,  ...,  0.8982,  0.6761,  0.9715]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[ 0.4072],\n",
      "        [ 0.8714],\n",
      "        [ 0.6963],\n",
      "        [ 1.6119],\n",
      "        [ 1.1461],\n",
      "        [ 0.2567],\n",
      "        [ 1.2069],\n",
      "        [-0.3783],\n",
      "        [ 0.9104],\n",
      "        [ 0.6548],\n",
      "        [ 0.8352],\n",
      "        [ 1.0458],\n",
      "        [ 1.9612],\n",
      "        [ 0.7260],\n",
      "        [ 0.9515],\n",
      "        [ 1.3110],\n",
      "        [-0.2398],\n",
      "        [ 1.1955],\n",
      "        [ 0.1330],\n",
      "        [ 0.2261],\n",
      "        [ 0.1715],\n",
      "        [ 1.1316],\n",
      "        [-0.7458],\n",
      "        [ 0.7165],\n",
      "        [ 1.2086],\n",
      "        [ 0.1484],\n",
      "        [-1.2050],\n",
      "        [-0.1831],\n",
      "        [ 1.2436],\n",
      "        [ 0.7696],\n",
      "        [ 1.0503],\n",
      "        [-1.5732],\n",
      "        [-0.0780],\n",
      "        [ 2.0351],\n",
      "        [ 0.5469],\n",
      "        [ 0.1465],\n",
      "        [ 0.6685],\n",
      "        [-1.0792],\n",
      "        [ 0.6582],\n",
      "        [ 0.5230],\n",
      "        [ 1.1385],\n",
      "        [ 1.3084],\n",
      "        [-0.1001],\n",
      "        [ 1.4252],\n",
      "        [ 0.7913],\n",
      "        [-0.5217],\n",
      "        [-1.0199],\n",
      "        [ 2.2556],\n",
      "        [ 0.8482],\n",
      "        [-0.4296],\n",
      "        [ 0.7301],\n",
      "        [ 0.2344],\n",
      "        [ 0.2163],\n",
      "        [ 0.4598],\n",
      "        [ 1.5495],\n",
      "        [ 2.6213],\n",
      "        [ 1.1547],\n",
      "        [-0.1932],\n",
      "        [ 1.2828],\n",
      "        [ 1.9106],\n",
      "        [ 0.1805],\n",
      "        [ 0.1000],\n",
      "        [ 1.3827],\n",
      "        [ 1.1348],\n",
      "        [ 0.5503],\n",
      "        [ 0.5176],\n",
      "        [ 0.8302],\n",
      "        [ 1.0906],\n",
      "        [ 0.9140],\n",
      "        [ 1.0082],\n",
      "        [ 0.3118],\n",
      "        [ 0.8642],\n",
      "        [ 1.5486],\n",
      "        [ 1.1191],\n",
      "        [ 0.4681],\n",
      "        [ 0.0922],\n",
      "        [ 2.3856],\n",
      "        [ 0.3758],\n",
      "        [-0.1445],\n",
      "        [ 0.9092],\n",
      "        [ 0.7764],\n",
      "        [ 1.2514],\n",
      "        [ 0.7420],\n",
      "        [ 0.1698],\n",
      "        [ 1.3195],\n",
      "        [ 0.8140],\n",
      "        [ 0.8656],\n",
      "        [ 0.3882],\n",
      "        [-0.0290],\n",
      "        [-0.6952],\n",
      "        [-0.3366],\n",
      "        [-0.2869],\n",
      "        [ 1.0945],\n",
      "        [-0.0081],\n",
      "        [-0.1147],\n",
      "        [-0.0128],\n",
      "        [ 0.0415],\n",
      "        [-0.3078],\n",
      "        [-0.5466],\n",
      "        [-0.0501],\n",
      "        [ 0.0118],\n",
      "        [ 0.3385],\n",
      "        [ 1.4704],\n",
      "        [ 0.7206],\n",
      "        [-0.5625],\n",
      "        [ 0.2834],\n",
      "        [ 2.0009],\n",
      "        [ 0.6291],\n",
      "        [ 2.1020],\n",
      "        [ 1.1370],\n",
      "        [ 1.5437],\n",
      "        [ 1.2294],\n",
      "        [ 1.3183],\n",
      "        [ 0.1154],\n",
      "        [ 1.3190],\n",
      "        [ 0.1750],\n",
      "        [ 0.1590],\n",
      "        [ 0.7841],\n",
      "        [-1.7627],\n",
      "        [ 2.4980],\n",
      "        [ 2.1351],\n",
      "        [ 0.8479],\n",
      "        [ 0.1838],\n",
      "        [ 0.2423],\n",
      "        [-0.1252],\n",
      "        [ 0.8936],\n",
      "        [ 0.6192],\n",
      "        [-0.1575],\n",
      "        [ 1.3795],\n",
      "        [-0.6298],\n",
      "        [ 1.2600],\n",
      "        [ 0.8955],\n",
      "        [ 0.9410],\n",
      "        [ 0.6512],\n",
      "        [ 2.2075],\n",
      "        [ 1.2054],\n",
      "        [-0.0721],\n",
      "        [ 0.5073],\n",
      "        [-0.8910],\n",
      "        [ 0.5276],\n",
      "        [ 0.8575],\n",
      "        [ 0.2947],\n",
      "        [ 0.7422],\n",
      "        [-0.1095],\n",
      "        [ 0.4005],\n",
      "        [ 0.6351],\n",
      "        [ 0.7467],\n",
      "        [-0.4047],\n",
      "        [ 0.4654],\n",
      "        [ 0.4896],\n",
      "        [ 0.9155],\n",
      "        [ 1.3208],\n",
      "        [ 1.0991],\n",
      "        [ 0.3698],\n",
      "        [ 1.7417],\n",
      "        [ 1.8963],\n",
      "        [ 1.8010],\n",
      "        [-0.6112],\n",
      "        [ 0.5590],\n",
      "        [-0.1437],\n",
      "        [ 0.2860],\n",
      "        [ 0.2366],\n",
      "        [ 0.1032],\n",
      "        [ 0.7164],\n",
      "        [ 1.2755],\n",
      "        [ 0.5972],\n",
      "        [-1.1053],\n",
      "        [ 1.1066],\n",
      "        [-0.7923],\n",
      "        [-1.2019],\n",
      "        [ 0.9709],\n",
      "        [ 1.1599],\n",
      "        [ 0.1178],\n",
      "        [ 1.5743],\n",
      "        [-0.3894],\n",
      "        [ 1.7721],\n",
      "        [ 0.2393],\n",
      "        [ 0.8254],\n",
      "        [ 0.6727],\n",
      "        [ 0.6896],\n",
      "        [ 0.3961],\n",
      "        [ 1.0073],\n",
      "        [-0.2454],\n",
      "        [-0.1822],\n",
      "        [ 1.2002],\n",
      "        [ 0.9558],\n",
      "        [ 1.0513],\n",
      "        [ 0.6996],\n",
      "        [ 0.4628],\n",
      "        [-0.1177],\n",
      "        [ 1.0364],\n",
      "        [ 0.2655],\n",
      "        [ 0.1306],\n",
      "        [-0.1119],\n",
      "        [-0.9749],\n",
      "        [ 0.0992],\n",
      "        [ 0.9419],\n",
      "        [ 0.6324],\n",
      "        [ 0.9424],\n",
      "        [ 0.3648],\n",
      "        [ 0.0540],\n",
      "        [ 1.0084],\n",
      "        [-0.1483],\n",
      "        [-0.2344],\n",
      "        [ 1.5446],\n",
      "        [ 0.7249],\n",
      "        [-0.4005],\n",
      "        [ 2.0199],\n",
      "        [-0.3795],\n",
      "        [ 1.1772],\n",
      "        [ 0.4099],\n",
      "        [-0.7553],\n",
      "        [-0.8971],\n",
      "        [ 1.1309],\n",
      "        [ 0.8908],\n",
      "        [ 0.6562],\n",
      "        [ 1.1980],\n",
      "        [ 0.3305],\n",
      "        [-0.6094],\n",
      "        [ 0.2896],\n",
      "        [ 0.8699],\n",
      "        [ 0.6329],\n",
      "        [ 1.0609],\n",
      "        [ 1.1681],\n",
      "        [ 0.5457],\n",
      "        [ 0.2825],\n",
      "        [ 0.7722],\n",
      "        [ 1.4582],\n",
      "        [ 2.1047],\n",
      "        [ 0.3655],\n",
      "        [ 0.6717],\n",
      "        [ 2.5420],\n",
      "        [ 0.3835],\n",
      "        [ 0.0039],\n",
      "        [ 1.3996],\n",
      "        [ 0.2904],\n",
      "        [ 0.6716],\n",
      "        [ 0.2895],\n",
      "        [ 1.5024],\n",
      "        [ 1.0495],\n",
      "        [ 1.1754],\n",
      "        [ 1.2182],\n",
      "        [-0.1779],\n",
      "        [ 0.8216],\n",
      "        [ 1.8478],\n",
      "        [ 0.8314],\n",
      "        [ 0.1278],\n",
      "        [ 1.0765],\n",
      "        [ 0.1764],\n",
      "        [ 0.4259],\n",
      "        [ 0.3069],\n",
      "        [ 0.7133],\n",
      "        [ 0.8928],\n",
      "        [ 0.5439],\n",
      "        [ 2.7506],\n",
      "        [ 1.2283]], grad_fn=<RsubBackward1>)\n",
      "Positive sample loss: 0.47268012166023254\n",
      "Negative sample loss: 1.504357099533081\n",
      "Total loss: 0.9885185956954956\n",
      "Score head-batch: tensor([[ 0.6344,  0.1849,  1.4273,  ...,  2.6253,  0.8657,  0.1854],\n",
      "        [-0.5091,  0.5474,  0.7909,  ...,  0.4185,  0.8519,  0.8820],\n",
      "        [ 0.4516, -0.0929,  1.0281,  ...,  0.0252, -0.8465, -0.3058],\n",
      "        ...,\n",
      "        [ 1.6678,  0.8222,  0.8028,  ...,  1.5451,  0.6931,  1.9441],\n",
      "        [ 0.2723, -0.3735,  0.2192,  ...,  0.1366, -0.3684,  0.1662],\n",
      "        [ 0.3379,  0.9368,  1.5995,  ...,  0.7701, -0.8846,  0.8338]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[ 0.0392],\n",
      "        [ 1.3968],\n",
      "        [-0.0309],\n",
      "        [-0.0576],\n",
      "        [ 0.9957],\n",
      "        [ 1.2222],\n",
      "        [ 0.0837],\n",
      "        [-0.8581],\n",
      "        [ 0.2571],\n",
      "        [ 2.0759],\n",
      "        [ 1.0129],\n",
      "        [ 1.2018],\n",
      "        [ 1.4330],\n",
      "        [-0.9141],\n",
      "        [ 0.5039],\n",
      "        [ 0.4158],\n",
      "        [-0.0881],\n",
      "        [-0.1081],\n",
      "        [ 1.2508],\n",
      "        [ 1.1003],\n",
      "        [ 0.5619],\n",
      "        [ 0.7951],\n",
      "        [ 0.6102],\n",
      "        [-1.0049],\n",
      "        [ 0.5373],\n",
      "        [ 0.6070],\n",
      "        [ 0.1133],\n",
      "        [ 0.4675],\n",
      "        [ 1.2827],\n",
      "        [ 0.7263],\n",
      "        [ 0.6533],\n",
      "        [-0.1455],\n",
      "        [ 1.1812],\n",
      "        [ 0.6379],\n",
      "        [ 1.0061],\n",
      "        [ 0.7926],\n",
      "        [ 0.6896],\n",
      "        [-0.2004],\n",
      "        [ 0.3917],\n",
      "        [ 1.0517],\n",
      "        [ 0.3424],\n",
      "        [-1.2472],\n",
      "        [ 2.1591],\n",
      "        [ 2.2287],\n",
      "        [ 0.5244],\n",
      "        [ 0.3457],\n",
      "        [ 0.8900],\n",
      "        [ 1.4918],\n",
      "        [ 0.0429],\n",
      "        [ 0.7986],\n",
      "        [ 0.1593],\n",
      "        [ 1.4885],\n",
      "        [ 0.7875],\n",
      "        [ 0.5115],\n",
      "        [ 1.1626],\n",
      "        [ 0.8248],\n",
      "        [ 1.4603],\n",
      "        [-0.2250],\n",
      "        [ 0.6219],\n",
      "        [-0.7848],\n",
      "        [ 0.1908],\n",
      "        [ 1.2670],\n",
      "        [ 0.3296],\n",
      "        [ 0.0171],\n",
      "        [ 0.9712],\n",
      "        [ 0.5183],\n",
      "        [-0.2982],\n",
      "        [ 1.6877],\n",
      "        [ 1.0510],\n",
      "        [-0.1022],\n",
      "        [-0.3626],\n",
      "        [ 0.3624],\n",
      "        [-0.3017],\n",
      "        [ 0.6314],\n",
      "        [ 1.7972],\n",
      "        [ 1.6850],\n",
      "        [ 2.1586],\n",
      "        [ 0.2224],\n",
      "        [ 1.7282],\n",
      "        [-1.2259],\n",
      "        [ 0.9265],\n",
      "        [ 0.0097],\n",
      "        [ 0.8973],\n",
      "        [-0.6302],\n",
      "        [-0.6187],\n",
      "        [ 0.1138],\n",
      "        [-0.8301],\n",
      "        [ 0.7041],\n",
      "        [ 0.9525],\n",
      "        [ 0.2555],\n",
      "        [ 0.3610],\n",
      "        [ 0.6247],\n",
      "        [ 0.6342],\n",
      "        [ 0.0426],\n",
      "        [ 0.7290],\n",
      "        [-0.3567],\n",
      "        [ 0.5385],\n",
      "        [ 1.4202],\n",
      "        [ 0.5657],\n",
      "        [ 0.5959],\n",
      "        [ 1.4977],\n",
      "        [ 0.4044],\n",
      "        [ 0.3291],\n",
      "        [ 0.4075],\n",
      "        [-0.3743],\n",
      "        [ 0.8495],\n",
      "        [-0.4164],\n",
      "        [-0.2904],\n",
      "        [ 1.1514],\n",
      "        [-0.9184],\n",
      "        [ 1.1987],\n",
      "        [-0.2919],\n",
      "        [ 1.9134],\n",
      "        [ 0.5587],\n",
      "        [ 1.2530],\n",
      "        [ 0.8564],\n",
      "        [ 0.1932],\n",
      "        [ 0.5867],\n",
      "        [-0.0026],\n",
      "        [ 0.6671],\n",
      "        [-0.0557],\n",
      "        [ 1.1762],\n",
      "        [ 1.3512],\n",
      "        [-0.0198],\n",
      "        [ 0.8542],\n",
      "        [ 1.3919],\n",
      "        [ 2.1139],\n",
      "        [-0.1318],\n",
      "        [ 0.3719],\n",
      "        [ 0.5616],\n",
      "        [ 1.2833],\n",
      "        [-0.4424],\n",
      "        [ 1.3739],\n",
      "        [ 0.4905],\n",
      "        [ 1.2669],\n",
      "        [ 2.0596],\n",
      "        [ 2.0354],\n",
      "        [ 1.1292],\n",
      "        [ 0.4415],\n",
      "        [ 0.0811],\n",
      "        [ 1.1113],\n",
      "        [ 1.7426],\n",
      "        [ 1.9567],\n",
      "        [ 0.3240],\n",
      "        [-0.1532],\n",
      "        [ 0.7175],\n",
      "        [-0.2735],\n",
      "        [ 0.5299],\n",
      "        [ 1.0448],\n",
      "        [-0.4233],\n",
      "        [-0.5707],\n",
      "        [-0.0832],\n",
      "        [ 0.8437],\n",
      "        [-0.6793],\n",
      "        [ 0.9987],\n",
      "        [ 1.2368],\n",
      "        [ 1.0841],\n",
      "        [-0.2191],\n",
      "        [ 1.2933],\n",
      "        [-0.2386],\n",
      "        [ 0.5717],\n",
      "        [ 0.2637],\n",
      "        [ 1.4191],\n",
      "        [ 0.4738],\n",
      "        [-0.6300],\n",
      "        [ 0.3081],\n",
      "        [ 0.3821],\n",
      "        [ 1.9944],\n",
      "        [ 1.1750],\n",
      "        [ 0.2757],\n",
      "        [ 0.6068],\n",
      "        [-0.2563],\n",
      "        [ 0.6455],\n",
      "        [-0.4918],\n",
      "        [ 0.9005],\n",
      "        [ 0.8153],\n",
      "        [ 0.4728],\n",
      "        [ 1.0166],\n",
      "        [ 0.3000],\n",
      "        [ 1.3444],\n",
      "        [-0.2277],\n",
      "        [ 1.3912],\n",
      "        [ 0.4774],\n",
      "        [ 0.6096],\n",
      "        [ 1.5157],\n",
      "        [ 0.7185],\n",
      "        [ 1.0192],\n",
      "        [ 0.3574],\n",
      "        [ 0.5329],\n",
      "        [-0.0943],\n",
      "        [ 0.3907],\n",
      "        [-0.0092],\n",
      "        [ 1.7453],\n",
      "        [ 0.4521],\n",
      "        [ 1.0611],\n",
      "        [ 0.6683],\n",
      "        [ 1.4072],\n",
      "        [ 1.5770],\n",
      "        [ 1.2236],\n",
      "        [ 1.3450],\n",
      "        [ 0.6008],\n",
      "        [-0.2470],\n",
      "        [ 0.9406],\n",
      "        [ 1.4366],\n",
      "        [ 1.0753],\n",
      "        [ 2.0450],\n",
      "        [ 0.3528],\n",
      "        [ 0.8173],\n",
      "        [ 0.1787],\n",
      "        [ 0.8021],\n",
      "        [ 0.1610],\n",
      "        [-0.0395],\n",
      "        [ 0.2040],\n",
      "        [ 0.2452],\n",
      "        [ 0.6332],\n",
      "        [-0.7551],\n",
      "        [ 0.8242],\n",
      "        [ 1.6896],\n",
      "        [ 1.4492],\n",
      "        [ 0.9878],\n",
      "        [ 1.4777],\n",
      "        [ 0.4909],\n",
      "        [ 1.6221],\n",
      "        [ 0.1029],\n",
      "        [ 1.2705],\n",
      "        [ 1.3822],\n",
      "        [ 1.4811],\n",
      "        [ 1.6998],\n",
      "        [-0.5197],\n",
      "        [ 1.0515],\n",
      "        [ 0.1091],\n",
      "        [-0.6147],\n",
      "        [ 0.3037],\n",
      "        [ 0.0121],\n",
      "        [ 0.4832],\n",
      "        [-0.0342],\n",
      "        [ 0.3686],\n",
      "        [ 0.2914],\n",
      "        [ 2.1475],\n",
      "        [-0.3303],\n",
      "        [ 0.9156],\n",
      "        [-0.2395],\n",
      "        [ 1.4388],\n",
      "        [ 0.3452],\n",
      "        [ 0.2108],\n",
      "        [ 0.6660],\n",
      "        [-0.3319],\n",
      "        [ 0.5196],\n",
      "        [ 1.1170],\n",
      "        [ 1.1913],\n",
      "        [ 0.5480],\n",
      "        [ 0.8415],\n",
      "        [ 1.0738],\n",
      "        [ 1.6532],\n",
      "        [ 0.5052],\n",
      "        [ 0.3370]], grad_fn=<RsubBackward1>)\n",
      "Positive sample loss: 0.4992208182811737\n",
      "Negative sample loss: 1.4125723838806152\n",
      "Total loss: 0.9558966159820557\n",
      "Score tail-batch: tensor([[ 0.6407,  0.5988,  0.7269,  ..., -0.1843,  2.0553,  0.1437],\n",
      "        [ 1.4336,  0.9693, -0.0038,  ...,  0.2081,  0.5777,  1.1469],\n",
      "        [ 0.6304,  1.8958,  1.5066,  ...,  1.7798,  0.8125,  1.1229],\n",
      "        ...,\n",
      "        [-0.7959, -1.0580,  0.1286,  ...,  0.6435, -0.4821, -0.6210],\n",
      "        [-0.8668, -0.4744,  0.8997,  ..., -0.7990,  1.4775, -1.7734],\n",
      "        [ 0.2474,  1.1958, -0.5534,  ...,  0.8037,  0.0676,  0.1103]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[ 0.4555],\n",
      "        [ 1.3056],\n",
      "        [ 1.7442],\n",
      "        [ 0.4424],\n",
      "        [ 1.4610],\n",
      "        [ 0.3561],\n",
      "        [ 0.9934],\n",
      "        [ 1.4015],\n",
      "        [ 0.3192],\n",
      "        [ 0.2868],\n",
      "        [ 1.4382],\n",
      "        [ 0.1757],\n",
      "        [ 0.9344],\n",
      "        [ 0.6944],\n",
      "        [ 0.5341],\n",
      "        [ 2.0786],\n",
      "        [ 0.9200],\n",
      "        [ 1.7642],\n",
      "        [ 1.0528],\n",
      "        [ 1.1613],\n",
      "        [ 0.6419],\n",
      "        [-0.5772],\n",
      "        [-0.7743],\n",
      "        [ 1.2724],\n",
      "        [ 1.2519],\n",
      "        [ 0.6045],\n",
      "        [ 0.7178],\n",
      "        [ 2.6730],\n",
      "        [ 1.1674],\n",
      "        [ 0.1982],\n",
      "        [ 0.0573],\n",
      "        [ 1.0163],\n",
      "        [ 1.3339],\n",
      "        [ 0.4768],\n",
      "        [ 0.6557],\n",
      "        [-0.1941],\n",
      "        [ 1.3946],\n",
      "        [ 1.3619],\n",
      "        [ 1.4909],\n",
      "        [ 0.3171],\n",
      "        [-0.5633],\n",
      "        [ 1.1558],\n",
      "        [-0.3111],\n",
      "        [ 1.1777],\n",
      "        [ 0.5458],\n",
      "        [ 0.1994],\n",
      "        [-0.3833],\n",
      "        [ 0.5899],\n",
      "        [ 1.0752],\n",
      "        [ 0.1878],\n",
      "        [ 1.1406],\n",
      "        [ 1.4148],\n",
      "        [ 0.7041],\n",
      "        [ 0.5048],\n",
      "        [-0.1524],\n",
      "        [ 0.2209],\n",
      "        [ 2.5868],\n",
      "        [-0.5689],\n",
      "        [ 0.0408],\n",
      "        [ 0.5471],\n",
      "        [ 0.9527],\n",
      "        [ 0.1699],\n",
      "        [ 1.1240],\n",
      "        [ 0.2407],\n",
      "        [ 1.1019],\n",
      "        [-0.4035],\n",
      "        [ 0.7926],\n",
      "        [ 0.5557],\n",
      "        [ 0.2535],\n",
      "        [ 0.0861],\n",
      "        [ 2.1036],\n",
      "        [ 1.4276],\n",
      "        [ 0.8303],\n",
      "        [ 0.7553],\n",
      "        [ 1.3900],\n",
      "        [-0.3296],\n",
      "        [ 0.3682],\n",
      "        [ 0.8878],\n",
      "        [ 0.7304],\n",
      "        [ 0.9241],\n",
      "        [-0.6362],\n",
      "        [-0.2558],\n",
      "        [ 0.6671],\n",
      "        [ 1.3706],\n",
      "        [-0.8404],\n",
      "        [ 0.5925],\n",
      "        [ 0.8916],\n",
      "        [ 0.4282],\n",
      "        [ 0.4914],\n",
      "        [ 2.4654],\n",
      "        [ 1.9771],\n",
      "        [ 0.1828],\n",
      "        [ 0.9845],\n",
      "        [ 0.2480],\n",
      "        [ 1.3059],\n",
      "        [ 1.6904],\n",
      "        [ 0.4787],\n",
      "        [-0.6308],\n",
      "        [ 0.6950],\n",
      "        [ 0.5342],\n",
      "        [ 0.1747],\n",
      "        [ 1.5563],\n",
      "        [ 0.5417],\n",
      "        [-0.6695],\n",
      "        [ 0.0218],\n",
      "        [-0.7506],\n",
      "        [ 1.5393],\n",
      "        [ 0.1524],\n",
      "        [ 1.4822],\n",
      "        [ 0.5395],\n",
      "        [-0.0057],\n",
      "        [ 0.7085],\n",
      "        [-0.0436],\n",
      "        [-0.3359],\n",
      "        [ 1.0980],\n",
      "        [ 0.1768],\n",
      "        [ 0.8760],\n",
      "        [ 0.8215],\n",
      "        [ 0.0213],\n",
      "        [ 0.6223],\n",
      "        [ 0.7487],\n",
      "        [ 0.4465],\n",
      "        [ 0.9744],\n",
      "        [ 0.9251],\n",
      "        [ 0.9218],\n",
      "        [ 0.0955],\n",
      "        [ 0.1252],\n",
      "        [ 1.3304],\n",
      "        [ 0.3533],\n",
      "        [ 1.4077],\n",
      "        [-0.2198],\n",
      "        [-0.1761],\n",
      "        [ 0.8689],\n",
      "        [-0.4834],\n",
      "        [ 0.5921],\n",
      "        [ 2.7650],\n",
      "        [-0.3770],\n",
      "        [ 1.4091],\n",
      "        [ 0.3542],\n",
      "        [-0.0036],\n",
      "        [ 0.5535],\n",
      "        [ 0.5342],\n",
      "        [-0.3603],\n",
      "        [ 1.0383],\n",
      "        [-0.2341],\n",
      "        [ 0.0820],\n",
      "        [-0.1394],\n",
      "        [ 0.5590],\n",
      "        [ 0.0943],\n",
      "        [ 0.2692],\n",
      "        [ 1.7357],\n",
      "        [ 0.0659],\n",
      "        [ 0.5949],\n",
      "        [ 2.0045],\n",
      "        [ 0.8214],\n",
      "        [-0.8666],\n",
      "        [ 1.3813],\n",
      "        [ 0.9550],\n",
      "        [ 0.8682],\n",
      "        [ 0.7844],\n",
      "        [ 1.9180],\n",
      "        [ 1.0404],\n",
      "        [ 1.1758],\n",
      "        [-0.2369],\n",
      "        [ 0.6835],\n",
      "        [-0.8859],\n",
      "        [ 1.4483],\n",
      "        [ 1.2756],\n",
      "        [ 1.1425],\n",
      "        [ 1.0053],\n",
      "        [ 0.6113],\n",
      "        [ 0.9084],\n",
      "        [ 1.0484],\n",
      "        [ 0.5217],\n",
      "        [ 0.0795],\n",
      "        [ 2.1141],\n",
      "        [ 1.0993],\n",
      "        [ 0.6753],\n",
      "        [ 0.9388],\n",
      "        [ 0.1339],\n",
      "        [ 0.0083],\n",
      "        [ 0.2983],\n",
      "        [ 0.9859],\n",
      "        [ 0.8664],\n",
      "        [-0.2059],\n",
      "        [ 1.1622],\n",
      "        [ 0.1965],\n",
      "        [ 1.0010],\n",
      "        [ 0.8082],\n",
      "        [ 0.0196],\n",
      "        [-0.2637],\n",
      "        [ 1.0824],\n",
      "        [ 0.7752],\n",
      "        [-0.4881],\n",
      "        [ 1.4084],\n",
      "        [-0.0184],\n",
      "        [ 1.8432],\n",
      "        [ 0.9941],\n",
      "        [ 1.3783],\n",
      "        [-0.3264],\n",
      "        [ 0.1528],\n",
      "        [-0.1522],\n",
      "        [-0.3618],\n",
      "        [ 1.1792],\n",
      "        [ 0.5247],\n",
      "        [ 1.1108],\n",
      "        [-0.4977],\n",
      "        [ 0.5242],\n",
      "        [ 0.3268],\n",
      "        [ 1.4068],\n",
      "        [-1.8848],\n",
      "        [ 0.1694],\n",
      "        [ 1.0627],\n",
      "        [ 1.5941],\n",
      "        [ 0.4320],\n",
      "        [ 0.1365],\n",
      "        [-0.7203],\n",
      "        [ 0.0714],\n",
      "        [ 1.2366],\n",
      "        [-0.1690],\n",
      "        [ 0.5651],\n",
      "        [-0.2529],\n",
      "        [ 1.7517],\n",
      "        [ 0.9881],\n",
      "        [-0.5948],\n",
      "        [ 0.3341],\n",
      "        [ 0.6358],\n",
      "        [ 1.5342],\n",
      "        [ 0.6752],\n",
      "        [ 0.5070],\n",
      "        [-1.1210],\n",
      "        [ 0.3215],\n",
      "        [ 0.3479],\n",
      "        [ 0.2672],\n",
      "        [ 1.3143],\n",
      "        [ 0.2124],\n",
      "        [ 0.8543],\n",
      "        [ 0.1915],\n",
      "        [-0.3523],\n",
      "        [ 0.1846],\n",
      "        [ 1.0328],\n",
      "        [ 0.3971],\n",
      "        [ 0.1877],\n",
      "        [ 0.4332],\n",
      "        [ 1.1237],\n",
      "        [ 0.7523],\n",
      "        [ 0.1464],\n",
      "        [ 1.1008],\n",
      "        [ 0.1582],\n",
      "        [ 0.2404],\n",
      "        [ 0.7182],\n",
      "        [ 1.2155],\n",
      "        [-0.6514],\n",
      "        [ 0.1023],\n",
      "        [-1.2989],\n",
      "        [ 0.3253]], grad_fn=<RsubBackward1>)\n",
      "Positive sample loss: 0.4683719277381897\n",
      "Negative sample loss: 1.4596877098083496\n",
      "Total loss: 0.9640297889709473\n",
      "Score head-batch: tensor([[ 1.1143,  1.0464,  1.5362,  ...,  1.1839, -0.4030, -0.5088],\n",
      "        [ 1.0176,  1.0854,  1.5426,  ...,  0.9008,  0.3398,  1.2743],\n",
      "        [ 0.7577,  1.2243,  0.7261,  ...,  1.0056, -0.2435, -0.8674],\n",
      "        ...,\n",
      "        [-0.2139,  0.5066,  0.6330,  ...,  1.3504,  0.5647,  0.8105],\n",
      "        [ 0.7317,  1.1884, -0.1484,  ...,  0.7233, -1.2279,  0.1729],\n",
      "        [ 1.0060, -0.6169,  0.3329,  ...,  0.8693,  1.7841,  0.6042]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[-0.2438],\n",
      "        [ 1.7852],\n",
      "        [ 0.2451],\n",
      "        [ 0.7979],\n",
      "        [ 0.6496],\n",
      "        [ 1.1441],\n",
      "        [ 0.2081],\n",
      "        [ 1.1627],\n",
      "        [ 1.4664],\n",
      "        [-0.9702],\n",
      "        [ 0.6810],\n",
      "        [-0.5373],\n",
      "        [ 1.7513],\n",
      "        [ 1.3662],\n",
      "        [ 1.2732],\n",
      "        [ 0.6436],\n",
      "        [ 1.3142],\n",
      "        [ 1.8582],\n",
      "        [ 0.4016],\n",
      "        [ 0.7282],\n",
      "        [ 0.5811],\n",
      "        [ 0.5059],\n",
      "        [ 1.0428],\n",
      "        [ 0.9332],\n",
      "        [ 0.8584],\n",
      "        [ 0.2948],\n",
      "        [-0.1860],\n",
      "        [-0.4769],\n",
      "        [-0.2186],\n",
      "        [-0.6791],\n",
      "        [ 1.1934],\n",
      "        [ 1.4695],\n",
      "        [ 0.9826],\n",
      "        [ 0.4615],\n",
      "        [-0.2462],\n",
      "        [ 0.3753],\n",
      "        [ 0.9513],\n",
      "        [-0.1574],\n",
      "        [ 0.3583],\n",
      "        [ 0.7121],\n",
      "        [ 1.3202],\n",
      "        [ 1.3440],\n",
      "        [ 1.1561],\n",
      "        [ 0.5730],\n",
      "        [ 0.6431],\n",
      "        [ 1.0721],\n",
      "        [ 1.8685],\n",
      "        [ 0.5630],\n",
      "        [ 1.2677],\n",
      "        [ 1.0956],\n",
      "        [ 2.4578],\n",
      "        [-0.0950],\n",
      "        [ 0.8571],\n",
      "        [-0.2651],\n",
      "        [ 0.1178],\n",
      "        [ 0.5812],\n",
      "        [ 1.2452],\n",
      "        [-0.8846],\n",
      "        [ 0.0975],\n",
      "        [ 0.8899],\n",
      "        [ 0.8273],\n",
      "        [ 1.5571],\n",
      "        [-0.0046],\n",
      "        [ 0.6904],\n",
      "        [ 0.3508],\n",
      "        [ 1.7006],\n",
      "        [ 0.3331],\n",
      "        [ 0.0150],\n",
      "        [ 1.5816],\n",
      "        [ 0.9466],\n",
      "        [ 0.5063],\n",
      "        [ 0.0332],\n",
      "        [ 0.8107],\n",
      "        [ 1.3859],\n",
      "        [ 2.3380],\n",
      "        [ 0.0110],\n",
      "        [-0.0708],\n",
      "        [-0.2135],\n",
      "        [ 3.4011],\n",
      "        [-0.1725],\n",
      "        [-0.3460],\n",
      "        [ 0.5048],\n",
      "        [ 0.7396],\n",
      "        [ 1.6316],\n",
      "        [ 0.0356],\n",
      "        [-0.0793],\n",
      "        [ 1.3001],\n",
      "        [ 0.3690],\n",
      "        [ 1.8098],\n",
      "        [ 0.6246],\n",
      "        [ 0.5600],\n",
      "        [ 0.0393],\n",
      "        [ 0.7551],\n",
      "        [ 0.8410],\n",
      "        [-0.0283],\n",
      "        [ 1.4123],\n",
      "        [-0.0796],\n",
      "        [-0.7575],\n",
      "        [ 0.2574],\n",
      "        [-0.3566],\n",
      "        [ 0.8270],\n",
      "        [ 0.3434],\n",
      "        [ 0.6533],\n",
      "        [ 0.8177],\n",
      "        [-0.1611],\n",
      "        [ 1.8016],\n",
      "        [ 0.9276],\n",
      "        [ 0.2821],\n",
      "        [ 0.1174],\n",
      "        [ 0.4352],\n",
      "        [ 1.8510],\n",
      "        [ 1.1412],\n",
      "        [ 1.5838],\n",
      "        [ 0.3583],\n",
      "        [-0.2334],\n",
      "        [ 0.6797],\n",
      "        [ 0.4443],\n",
      "        [ 1.3107],\n",
      "        [-0.1564],\n",
      "        [ 0.8370],\n",
      "        [-0.5512],\n",
      "        [-0.5777],\n",
      "        [-0.2494],\n",
      "        [ 1.2154],\n",
      "        [ 0.4600],\n",
      "        [ 0.8004],\n",
      "        [ 1.1467],\n",
      "        [ 0.7502],\n",
      "        [ 0.4845],\n",
      "        [ 1.0179],\n",
      "        [-0.8891],\n",
      "        [ 0.6120],\n",
      "        [ 2.3229],\n",
      "        [-0.0735],\n",
      "        [-0.2656],\n",
      "        [ 0.4369],\n",
      "        [ 0.6725],\n",
      "        [ 0.7670],\n",
      "        [ 0.0365],\n",
      "        [-0.1119],\n",
      "        [-0.1331],\n",
      "        [-0.4862],\n",
      "        [ 0.5697],\n",
      "        [ 0.9796],\n",
      "        [-0.2262],\n",
      "        [ 0.8911],\n",
      "        [ 0.2724],\n",
      "        [ 0.0525],\n",
      "        [ 0.4440],\n",
      "        [ 1.1434],\n",
      "        [ 0.7045],\n",
      "        [ 0.2623],\n",
      "        [ 0.2372],\n",
      "        [ 1.3879],\n",
      "        [ 0.7546],\n",
      "        [-0.2222],\n",
      "        [-0.6038],\n",
      "        [ 1.3212],\n",
      "        [-0.5035],\n",
      "        [ 0.7424],\n",
      "        [ 1.2451],\n",
      "        [ 0.2553],\n",
      "        [ 0.9293],\n",
      "        [ 2.6765],\n",
      "        [ 0.0696],\n",
      "        [ 0.3732],\n",
      "        [ 1.2909],\n",
      "        [ 1.0099],\n",
      "        [ 0.8089],\n",
      "        [ 1.5491],\n",
      "        [-0.1546],\n",
      "        [ 1.4936],\n",
      "        [ 1.8734],\n",
      "        [-0.0056],\n",
      "        [ 0.3950],\n",
      "        [ 0.8783],\n",
      "        [ 0.2777],\n",
      "        [ 0.6911],\n",
      "        [ 0.7733],\n",
      "        [ 0.1511],\n",
      "        [ 0.3568],\n",
      "        [ 1.2453],\n",
      "        [ 0.4376],\n",
      "        [ 1.9989],\n",
      "        [ 1.4738],\n",
      "        [-0.3902],\n",
      "        [ 0.7551],\n",
      "        [ 0.4568],\n",
      "        [-0.0630],\n",
      "        [-0.5512],\n",
      "        [ 0.6956],\n",
      "        [ 0.5211],\n",
      "        [-0.4012],\n",
      "        [ 1.5605],\n",
      "        [ 0.1687],\n",
      "        [ 0.9116],\n",
      "        [ 0.1124],\n",
      "        [ 1.0838],\n",
      "        [ 0.4141],\n",
      "        [ 1.2252],\n",
      "        [ 0.7376],\n",
      "        [ 2.1424],\n",
      "        [-0.0228],\n",
      "        [ 1.1521],\n",
      "        [ 0.5661],\n",
      "        [ 1.0172],\n",
      "        [ 1.3815],\n",
      "        [-0.2477],\n",
      "        [ 0.4940],\n",
      "        [-0.1274],\n",
      "        [ 1.4203],\n",
      "        [ 0.8956],\n",
      "        [ 1.0126],\n",
      "        [-0.1156],\n",
      "        [ 0.8386],\n",
      "        [ 0.8159],\n",
      "        [ 0.9301],\n",
      "        [ 0.1557],\n",
      "        [ 0.3467],\n",
      "        [ 1.3017],\n",
      "        [ 2.0480],\n",
      "        [ 0.1740],\n",
      "        [ 0.8331],\n",
      "        [-0.5379],\n",
      "        [ 0.8501],\n",
      "        [ 0.8054],\n",
      "        [-0.7329],\n",
      "        [ 0.2090],\n",
      "        [ 1.0588],\n",
      "        [ 0.7288],\n",
      "        [-0.4959],\n",
      "        [ 1.5395],\n",
      "        [ 1.7520],\n",
      "        [ 0.5113],\n",
      "        [ 1.1692],\n",
      "        [ 1.1467],\n",
      "        [ 0.7851],\n",
      "        [ 0.5477],\n",
      "        [-0.3853],\n",
      "        [ 1.8261],\n",
      "        [ 0.4070],\n",
      "        [ 1.4743],\n",
      "        [ 1.3064],\n",
      "        [ 0.3018],\n",
      "        [ 0.1697],\n",
      "        [-0.7981],\n",
      "        [ 1.1162],\n",
      "        [ 1.3313],\n",
      "        [ 0.3924],\n",
      "        [ 2.4002],\n",
      "        [ 0.0606],\n",
      "        [ 0.7233],\n",
      "        [ 0.8888],\n",
      "        [-0.0061],\n",
      "        [-1.0353],\n",
      "        [ 0.3995]], grad_fn=<RsubBackward1>)\n",
      "Positive sample loss: 0.42895615100860596\n",
      "Negative sample loss: 1.503427267074585\n",
      "Total loss: 0.9661917090415955\n",
      "Score tail-batch: tensor([[ 1.2779, -0.6803, -0.8945,  ..., -0.2189,  0.3489, -1.6840],\n",
      "        [ 0.3484,  2.0695,  1.0323,  ...,  0.6919, -0.9755,  0.8991],\n",
      "        [ 0.0996, -0.4557,  0.4378,  ...,  0.4244,  0.3844, -0.0256],\n",
      "        ...,\n",
      "        [-0.0736,  1.2505,  1.1274,  ..., -0.0726,  0.5195,  0.4762],\n",
      "        [ 1.0239, -2.5229, -1.0842,  ...,  0.3661,  0.1884,  0.1071],\n",
      "        [ 0.8644,  0.8420,  0.1668,  ..., -0.0084,  0.8228,  0.1657]],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Score single: tensor([[ 0.2144],\n",
      "        [ 0.3573],\n",
      "        [-0.9875],\n",
      "        [ 0.9357],\n",
      "        [-0.0701],\n",
      "        [ 0.7289],\n",
      "        [ 1.2108],\n",
      "        [-0.5251],\n",
      "        [-0.7999],\n",
      "        [ 0.6273],\n",
      "        [-0.3036],\n",
      "        [ 0.0422],\n",
      "        [ 1.0176],\n",
      "        [-0.1175],\n",
      "        [-0.7363],\n",
      "        [ 0.0674],\n",
      "        [ 1.8594],\n",
      "        [ 0.4432],\n",
      "        [-0.0264],\n",
      "        [ 1.4094],\n",
      "        [-0.0037],\n",
      "        [ 0.3887],\n",
      "        [ 0.4968],\n",
      "        [ 0.2923],\n",
      "        [ 1.4717],\n",
      "        [ 0.4345],\n",
      "        [-0.0930],\n",
      "        [ 0.4911],\n",
      "        [ 0.8681],\n",
      "        [-0.4412],\n",
      "        [ 0.8094],\n",
      "        [ 1.6503],\n",
      "        [ 0.7718],\n",
      "        [ 0.4098],\n",
      "        [ 1.5615],\n",
      "        [ 0.3217],\n",
      "        [ 0.2184],\n",
      "        [ 2.1210],\n",
      "        [ 0.8609],\n",
      "        [ 1.9341],\n",
      "        [ 0.8929],\n",
      "        [-0.5147],\n",
      "        [ 1.5090],\n",
      "        [ 0.8722],\n",
      "        [ 1.1949],\n",
      "        [ 0.5578],\n",
      "        [ 0.6766],\n",
      "        [-0.0303],\n",
      "        [ 2.1624],\n",
      "        [ 0.0982],\n",
      "        [-0.1349],\n",
      "        [-0.3406],\n",
      "        [ 0.5258],\n",
      "        [ 0.0357],\n",
      "        [-0.4787],\n",
      "        [ 0.7824],\n",
      "        [ 0.2380],\n",
      "        [ 0.9170],\n",
      "        [-0.0371],\n",
      "        [ 0.9475],\n",
      "        [ 1.6349],\n",
      "        [-0.6372],\n",
      "        [-0.9722],\n",
      "        [ 2.3984],\n",
      "        [-0.0154],\n",
      "        [ 1.0867],\n",
      "        [ 1.2786],\n",
      "        [ 0.9948],\n",
      "        [-0.1601],\n",
      "        [ 0.9109],\n",
      "        [-0.6744],\n",
      "        [ 0.4763],\n",
      "        [ 2.0218],\n",
      "        [ 1.7785],\n",
      "        [ 1.1445],\n",
      "        [ 1.2416],\n",
      "        [ 0.3235],\n",
      "        [ 0.6727],\n",
      "        [ 0.3687],\n",
      "        [ 0.7377],\n",
      "        [-0.5024],\n",
      "        [ 1.0913],\n",
      "        [ 0.2357],\n",
      "        [-0.1869],\n",
      "        [-0.4653],\n",
      "        [ 0.7635],\n",
      "        [ 1.4498],\n",
      "        [ 0.4105],\n",
      "        [ 1.1965],\n",
      "        [ 1.1915],\n",
      "        [ 0.8247],\n",
      "        [ 0.4106],\n",
      "        [ 0.0452],\n",
      "        [ 0.7174],\n",
      "        [ 1.5153],\n",
      "        [ 0.5659],\n",
      "        [ 1.6372],\n",
      "        [ 0.7914],\n",
      "        [ 1.0022],\n",
      "        [ 0.0194],\n",
      "        [ 1.8770],\n",
      "        [ 0.6183],\n",
      "        [ 0.3963],\n",
      "        [-0.4195],\n",
      "        [ 1.7260],\n",
      "        [ 1.7555],\n",
      "        [ 1.6161],\n",
      "        [ 1.0221],\n",
      "        [ 0.6264],\n",
      "        [-0.2127],\n",
      "        [ 1.6538],\n",
      "        [ 1.0655],\n",
      "        [-0.1173],\n",
      "        [-0.0743],\n",
      "        [-0.4583],\n",
      "        [ 0.9119],\n",
      "        [ 0.6613],\n",
      "        [ 0.8448],\n",
      "        [ 0.5282],\n",
      "        [-0.0197],\n",
      "        [ 0.6893],\n",
      "        [-1.1607],\n",
      "        [ 1.3345],\n",
      "        [-0.6167],\n",
      "        [-0.3839],\n",
      "        [-0.1738],\n",
      "        [ 2.5334],\n",
      "        [ 1.4521],\n",
      "        [ 0.7569],\n",
      "        [ 0.6842],\n",
      "        [ 0.6546],\n",
      "        [ 0.3179],\n",
      "        [ 0.2610],\n",
      "        [ 0.7949],\n",
      "        [ 0.6051],\n",
      "        [ 0.9966],\n",
      "        [ 0.9885],\n",
      "        [-0.1786],\n",
      "        [ 1.1891],\n",
      "        [ 0.0079],\n",
      "        [ 0.7921],\n",
      "        [-0.0833],\n",
      "        [-1.4434],\n",
      "        [ 0.8007],\n",
      "        [ 0.9362],\n",
      "        [ 0.5275],\n",
      "        [-0.1820],\n",
      "        [-1.0815],\n",
      "        [ 0.5487],\n",
      "        [-1.1385],\n",
      "        [ 1.0533],\n",
      "        [ 0.9189],\n",
      "        [ 1.3862],\n",
      "        [ 1.4882],\n",
      "        [ 0.7151],\n",
      "        [ 0.1562],\n",
      "        [ 0.6465],\n",
      "        [ 1.4427],\n",
      "        [-0.2816],\n",
      "        [ 0.4970],\n",
      "        [ 0.5448],\n",
      "        [ 0.1521],\n",
      "        [ 1.8496],\n",
      "        [ 0.5426],\n",
      "        [ 0.7211],\n",
      "        [-0.3680],\n",
      "        [ 1.0629],\n",
      "        [-0.2033],\n",
      "        [ 0.0756],\n",
      "        [ 1.3947],\n",
      "        [-0.4587],\n",
      "        [ 1.0671],\n",
      "        [-0.2406],\n",
      "        [-0.1016],\n",
      "        [-0.1421],\n",
      "        [ 0.6892],\n",
      "        [ 0.4527],\n",
      "        [ 0.5696],\n",
      "        [ 1.4464],\n",
      "        [-1.0940],\n",
      "        [ 0.3506],\n",
      "        [-0.4284],\n",
      "        [ 0.3785],\n",
      "        [ 0.8292],\n",
      "        [ 1.4195],\n",
      "        [ 0.8301],\n",
      "        [-0.4564],\n",
      "        [ 0.1317],\n",
      "        [ 0.6724],\n",
      "        [ 0.9478],\n",
      "        [-0.1420],\n",
      "        [ 1.6718],\n",
      "        [-0.1161],\n",
      "        [ 0.6022],\n",
      "        [ 1.1280],\n",
      "        [ 0.6904],\n",
      "        [ 1.0385],\n",
      "        [ 0.9619],\n",
      "        [ 0.6647],\n",
      "        [ 0.3113],\n",
      "        [ 1.5418],\n",
      "        [-1.2767],\n",
      "        [ 0.9845],\n",
      "        [ 0.3577],\n",
      "        [ 1.8306],\n",
      "        [ 0.9142],\n",
      "        [-0.0589],\n",
      "        [ 0.4439],\n",
      "        [-1.2090],\n",
      "        [ 0.0051],\n",
      "        [ 1.0093],\n",
      "        [ 1.1496],\n",
      "        [ 0.5038],\n",
      "        [-0.5475],\n",
      "        [ 0.3041],\n",
      "        [ 2.0615],\n",
      "        [ 1.1537],\n",
      "        [ 0.5229],\n",
      "        [ 0.4208],\n",
      "        [ 1.7669],\n",
      "        [-0.0096],\n",
      "        [ 0.2963],\n",
      "        [ 0.6645],\n",
      "        [ 1.7493],\n",
      "        [ 0.1023],\n",
      "        [ 0.7687],\n",
      "        [ 0.0240],\n",
      "        [ 0.5055],\n",
      "        [ 2.3148],\n",
      "        [ 0.7750],\n",
      "        [ 1.1419],\n",
      "        [-0.0381],\n",
      "        [-0.1137],\n",
      "        [ 1.0529],\n",
      "        [ 1.1021],\n",
      "        [ 0.7374],\n",
      "        [-0.3132],\n",
      "        [ 1.2253],\n",
      "        [ 0.6125],\n",
      "        [ 0.3154],\n",
      "        [-0.5959],\n",
      "        [-0.2448],\n",
      "        [ 0.6750],\n",
      "        [ 0.0975],\n",
      "        [-0.6766],\n",
      "        [ 1.4548],\n",
      "        [ 0.9190],\n",
      "        [-0.6070],\n",
      "        [ 0.4886],\n",
      "        [ 0.9598],\n",
      "        [ 2.5138],\n",
      "        [ 1.1626],\n",
      "        [ 0.1873],\n",
      "        [ 0.8192],\n",
      "        [ 0.1160],\n",
      "        [ 0.0390]], grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2207/3250963404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# torch.manual_seed(random_seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# torch.cuda.manual_seed_all(random_seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'--max_steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'500'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--save_steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'500'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--valid_steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--datadir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../persistent/data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2207/3250963404.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mloss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkge_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkge_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2207/2184753815.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, train_iterator, args)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mregularization_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Training and Testing Knowledge Graph Embedding Models',\n",
    "        usage='train.py [<args>] [-h | --help]'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('--cuda', action='store_true', help='use GPU', default=False)\n",
    "    parser.add_argument('--CUDA_DEVISE', default='1', help='')\n",
    "\n",
    "    parser.add_argument('--do_train', action='store_true', default=True)\n",
    "    parser.add_argument('--do_valid', action='store_true')\n",
    "    parser.add_argument('--do_test', action='store_true')\n",
    "    parser.add_argument('--evaluate_train', action='store_true', help='Evaluate on training data', default=False)\n",
    "\n",
    "    parser.add_argument('--datadir', type=str, default='data')\n",
    "    parser.add_argument('--dataset', type=str, default='ontology')\n",
    "\n",
    "    parser.add_argument('-save', '--save_path', type=str)\n",
    "\n",
    "    parser.add_argument('--model', default='TransE', type=str)\n",
    "    parser.add_argument('-de', '--double_entity_embedding', action='store_true')\n",
    "    parser.add_argument('-dr', '--double_relation_embedding', action='store_true')\n",
    "\n",
    "    parser.add_argument('-n', '--negative_sample_size', default=1024, type=int)\n",
    "    parser.add_argument('-d', '--hidden_dim', default=100, type=int)\n",
    "    parser.add_argument('-g', '--gamma', default=12, type=float)\n",
    "    parser.add_argument('-adv', '--negative_adversarial_sampling', action='store_true', default=True)\n",
    "    parser.add_argument('-a', '--adversarial_temperature', default=1, type=float)\n",
    "    parser.add_argument('-b', '--batch_size', default=256, type=int)\n",
    "    parser.add_argument('-r', '--regularization', default=0.0, type=float)\n",
    "    parser.add_argument('--test_batch_size', default=8, type=int, help='valid/test batch size')\n",
    "    parser.add_argument('--uni_weight', action='store_true',\n",
    "                        help='Otherwise use subsampling weighting like in word2vec')\n",
    "\n",
    "    parser.add_argument('-lr', '--learning_rate', default=0.00005, type=float)\n",
    "    parser.add_argument('-cpu', '--cpu_num', default=10, type=int)\n",
    "\n",
    "\n",
    "    parser.add_argument('--max_steps', default=80000, type=int)\n",
    "    parser.add_argument('--warm_up_steps', default=None, type=int)\n",
    "\n",
    "    parser.add_argument('--save_steps', default=1000, type=int)\n",
    "    parser.add_argument('--valid_steps', default=1000, type=int)\n",
    "    parser.add_argument('--print_steps', default=100, type=int, help='train log every xx steps')\n",
    "    parser.add_argument('--test_log_steps', default=1000, type=int, help='valid/test log every xx steps')\n",
    "\n",
    "    parser.add_argument('--nentity', type=int, default=0, help='DO NOT MANUALLY SET')\n",
    "    parser.add_argument('--nrelation', type=int, default=0, help='DO NOT MANUALLY SET')\n",
    "\n",
    "    return parser.parse_args(args)\n",
    "\n",
    "\n",
    "def save_embeddings(model, step, args):\n",
    "    '''\n",
    "    Save the parameters of the model and the optimizer,\n",
    "    as well as some other variables such as step and learning_rate\n",
    "    '''\n",
    "    file_name = 'entity_' + str(step)\n",
    "    entity_embedding = model.entity_embedding.detach().cpu().numpy()\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(args.save_path, file_name),\n",
    "        entity_embedding\n",
    "    )\n",
    "\n",
    "    rel_file_name = 'relation_' + str(step)\n",
    "    relation_embedding = model.relation_embedding.detach().cpu().numpy()\n",
    "    np.save(\n",
    "        os.path.join(args.save_path, rel_file_name),\n",
    "        relation_embedding\n",
    "    )\n",
    "\n",
    "\n",
    "def read_triple(file_path, entity2id, relation2id):\n",
    "    '''\n",
    "    Read triples and map them into ids.\n",
    "    '''\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            h, r, t = line.strip().split('\\t')\n",
    "            triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
    "    return triples\n",
    "\n",
    "\n",
    "def log_metrics(mode, step, metrics):\n",
    "    '''\n",
    "    Print the evaluation logs\n",
    "    '''\n",
    "    for metric in metrics:\n",
    "        print('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.CUDA_DEVISE\n",
    "\n",
    "    args.data_path = os.path.join(args.datadir, args.dataset)\n",
    "\n",
    "\n",
    "    # if args.init_checkpoint:\n",
    "    #     override_config(args)\n",
    "    if args.data_path is None:\n",
    "        raise ValueError('data_path and dataset must be choosed.')\n",
    "\n",
    "    args.save_path = os.path.join(args.data_path, 'save_onto_embeds')\n",
    "\n",
    "    # if args.do_train and args.save_path is None:\n",
    "    #     raise ValueError('Where do you want to save your trained model?')\n",
    "\n",
    "    if args.save_path and not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "\n",
    "    with open(os.path.join(args.data_path, 'entities.dict')) as fin:\n",
    "        entity2id = dict()\n",
    "        for line in fin:\n",
    "            eid, entity = line.strip().split('\\t')\n",
    "            entity2id[entity] = int(eid)\n",
    "\n",
    "    with open(os.path.join(args.data_path, 'relations.dict')) as fin:\n",
    "        relation2id = dict()\n",
    "        for line in fin:\n",
    "            rid, relation = line.strip().split('\\t')\n",
    "            relation2id[relation] = int(rid)\n",
    "\n",
    "    nentity = len(entity2id)\n",
    "    nrelation = len(relation2id)\n",
    "\n",
    "    args.nentity = nentity\n",
    "    args.nrelation = nrelation\n",
    "\n",
    "    print('Model: %s' % args.model)\n",
    "    # print('Data Path: %s' % args.data_path + \"/\" + args.dataset)\n",
    "    print('#entity num: %d' % nentity)\n",
    "    print('#relation num: %d' % nrelation)\n",
    "\n",
    "    all_triples = read_triple(os.path.join(args.data_path, 'triples.txt'), entity2id,\n",
    "                              relation2id)\n",
    "    print('#total triples num: %d' % len(all_triples))\n",
    "\n",
    "\n",
    "    # All true triples\n",
    "    all_true_triples = all_triples\n",
    "\n",
    "    kge_model = KGEModel(\n",
    "        model_name=args.model,\n",
    "        nentity=nentity,\n",
    "        nrelation=nrelation,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        gamma=args.gamma,\n",
    "        double_entity_embedding=args.double_entity_embedding,\n",
    "        double_relation_embedding=args.double_relation_embedding\n",
    "    )\n",
    "\n",
    "    # logging.info('Model Parameter Configuration:')\n",
    "    # for name, param in kge_model.named_parameters():\n",
    "    #     logging.info('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "\n",
    "    #if args.cuda:\n",
    "    #    kge_model = kge_model.cuda()\n",
    "\n",
    "    if args.do_train:\n",
    "        # Set training dataloader iterator\n",
    "        train_dataloader_head = DataLoader(\n",
    "            TrainDataset(all_triples, nentity, nrelation, args.negative_sample_size, 'head-batch'),\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=max(1, args.cpu_num // 2),\n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        train_dataloader_tail = DataLoader(\n",
    "            TrainDataset(all_triples, nentity, nrelation, args.negative_sample_size, 'tail-batch'),\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=max(1, args.cpu_num // 2),\n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)\n",
    "\n",
    "        # Set training configuration\n",
    "        current_learning_rate = args.learning_rate\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate\n",
    "        )\n",
    "        if args.warm_up_steps:\n",
    "            warm_up_steps = args.warm_up_steps\n",
    "        else:\n",
    "            warm_up_steps = args.max_steps // 2\n",
    "\n",
    "    print('Ramdomly Initializing %s Model...' % args.model)\n",
    "\n",
    "    # step = init_step\n",
    "\n",
    "    print('------ Start Training...')\n",
    "    print('batch_size = %d' % args.batch_size)\n",
    "    print('negative sample size = %d' % args.negative_sample_size)\n",
    "    print('hidden_dim = %d' % args.hidden_dim)\n",
    "    print('gamma = %f' % args.gamma)\n",
    "    print('negative_adversarial_sampling = %s' % str(args.negative_adversarial_sampling))\n",
    "\n",
    "    if args.negative_adversarial_sampling:\n",
    "        print('adversarial_temperature = %f' % args.adversarial_temperature)\n",
    "\n",
    "    print(\"learning rate = %f\" % current_learning_rate)\n",
    "\n",
    "    # Set valid dataloader as it would be evaluated during training\n",
    "\n",
    "    if args.do_train:\n",
    "\n",
    "        train_losses = []\n",
    "\n",
    "        # Training Loop\n",
    "        for step in range(1, args.max_steps + 1):\n",
    "\n",
    "            loss_values = kge_model.train_step(kge_model, optimizer, train_iterator, args)\n",
    "\n",
    "            train_losses.append(loss_values)\n",
    "\n",
    "            if step >= warm_up_steps:\n",
    "                current_learning_rate = current_learning_rate / 10\n",
    "                print('Change learning_rate to %f at step %d' % (current_learning_rate, step))\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "                    lr=current_learning_rate\n",
    "                )\n",
    "                warm_up_steps = warm_up_steps * 3\n",
    "\n",
    "            if step % args.print_steps == 0:\n",
    "                pos_sample_loss = sum([losses['pos_sample_loss'] for losses in train_losses]) / len(train_losses)\n",
    "                neg_sample_loss = sum([losses['neg_sample_loss'] for losses in train_losses]) / len(train_losses)\n",
    "                loss1 = sum([losses['loss'] for losses in train_losses]) / len(train_losses)\n",
    "\n",
    "                # log_metrics('Training average', step, metrics)\n",
    "                print('Training Step: %d; average -> pos_sample_loss: %f; neg_sample_loss: %f; loss: %f' %\n",
    "                      (step, pos_sample_loss, neg_sample_loss, loss1))\n",
    "                train_losses = []\n",
    "\n",
    "            if step % args.save_steps == 0:\n",
    "                save_embeddings(kge_model, step, args)\n",
    "\n",
    "            if args.evaluate_train and step % args.valid_steps == 0:\n",
    "                print('------ Evaluating on Training Dataset...')\n",
    "                metrics = kge_model.test_step(kge_model, all_triples, all_true_triples, args)\n",
    "                log_metrics('Test', step, metrics)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # random_seed = random.randint(1, 10000)\n",
    "    # random_seed = 5487\n",
    "    #\n",
    "    # print(\"random seed:\", random_seed)\n",
    "    # random.seed(random_seed)\n",
    "    # torch.manual_seed(random_seed)\n",
    "    # torch.cuda.manual_seed_all(random_seed)\n",
    "    main(parse_args(args=['--max_steps', '500', '--save_steps', '500', '--valid_steps', '100', '--datadir', '../persistent/data']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
